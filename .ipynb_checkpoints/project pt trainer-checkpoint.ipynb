{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv(\"dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(file.kesimpulan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=pd.concat([file,dummies],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no id</th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>tinggi (m)</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "      <th>kesimpulan</th>\n",
       "      <th>lari</th>\n",
       "      <th>normal</th>\n",
       "      <th>obesitas</th>\n",
       "      <th>over weight</th>\n",
       "      <th>under weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.50</td>\n",
       "      <td>under weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.99</td>\n",
       "      <td>under weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>17.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.90</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.00</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>69.0944</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.99</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>69.1200</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.00</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>69.1456</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.01</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>39.3750</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>17.50</td>\n",
       "      <td>under weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>40.4775</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>17.99</td>\n",
       "      <td>under weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>40.5000</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>56.2275</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.99</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>56.2500</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>60.7500</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.00</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>60.7725</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.01</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>61.8750</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.50</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.71</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>87.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1.89</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.36</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>110.0000</td>\n",
       "      <td>185</td>\n",
       "      <td>1.85</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.14</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>104.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1.95</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.35</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>61.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>1.49</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.48</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>104.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1.89</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.11</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>92.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1.47</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.57</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1.54</td>\n",
       "      <td>Male</td>\n",
       "      <td>46.80</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.73</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>103.0000</td>\n",
       "      <td>169</td>\n",
       "      <td>1.69</td>\n",
       "      <td>Female</td>\n",
       "      <td>36.06</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>81.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1.95</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.30</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>159</td>\n",
       "      <td>1.59</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.64</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>192</td>\n",
       "      <td>1.92</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.40</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>1.55</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.23</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>488</td>\n",
       "      <td>142.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1.47</td>\n",
       "      <td>Male</td>\n",
       "      <td>65.71</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>489</td>\n",
       "      <td>112.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1.54</td>\n",
       "      <td>Male</td>\n",
       "      <td>47.23</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>490</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>178</td>\n",
       "      <td>1.78</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.52</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>491</td>\n",
       "      <td>153.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1.95</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.24</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>492</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>1.67</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.33</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>493</td>\n",
       "      <td>131.0000</td>\n",
       "      <td>183</td>\n",
       "      <td>1.83</td>\n",
       "      <td>Male</td>\n",
       "      <td>39.12</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>494</td>\n",
       "      <td>142.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>1.64</td>\n",
       "      <td>Female</td>\n",
       "      <td>52.80</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>495</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>1.67</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.95</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>496</td>\n",
       "      <td>55.0000</td>\n",
       "      <td>151</td>\n",
       "      <td>1.51</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.12</td>\n",
       "      <td>over weight</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>497</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1.47</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.52</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>498</td>\n",
       "      <td>115.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>1.55</td>\n",
       "      <td>Female</td>\n",
       "      <td>47.87</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>499</td>\n",
       "      <td>108.0000</td>\n",
       "      <td>172</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Female</td>\n",
       "      <td>36.51</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>500</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>142</td>\n",
       "      <td>1.42</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.65</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>501</td>\n",
       "      <td>85.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>1.46</td>\n",
       "      <td>Male</td>\n",
       "      <td>39.88</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>502</td>\n",
       "      <td>115.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>1.88</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.54</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>503</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1.73</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.09</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>504</td>\n",
       "      <td>109.0000</td>\n",
       "      <td>160</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.58</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>505</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>1.87</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.88</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>506</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>1.98</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.69</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>507</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>1.79</td>\n",
       "      <td>Female</td>\n",
       "      <td>46.82</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>508</td>\n",
       "      <td>59.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>1.64</td>\n",
       "      <td>Female</td>\n",
       "      <td>21.94</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>509</td>\n",
       "      <td>147.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>1.46</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.96</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>510</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>1.98</td>\n",
       "      <td>Female</td>\n",
       "      <td>12.75</td>\n",
       "      <td>under weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>511</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>170</td>\n",
       "      <td>1.70</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.34</td>\n",
       "      <td>normal</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>512</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>152</td>\n",
       "      <td>1.52</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.42</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>513</td>\n",
       "      <td>153.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.00</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>514</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>184</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.74</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>515</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>141</td>\n",
       "      <td>1.41</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.41</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>516</td>\n",
       "      <td>95.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>42.22</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>517</td>\n",
       "      <td>131.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1.73</td>\n",
       "      <td>Male</td>\n",
       "      <td>43.77</td>\n",
       "      <td>obesitas</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no id     berat  tingg  tinggi (m)  gender  berat ideal    kesimpulan  \\\n",
       "0        1   42.2400    160        1.60    Male        16.50  under weight   \n",
       "1        2   43.4944    160        1.60    Male        16.99  under weight   \n",
       "2        3   43.5200    160        1.60    Male        17.00        normal   \n",
       "3        4   58.6240    160        1.60    Male        22.90        normal   \n",
       "4        5   58.8800    160        1.60    Male        23.00   over weight   \n",
       "5        6   69.0944    160        1.60    Male        26.99   over weight   \n",
       "6        7   69.1200    160        1.60    Male        27.00      obesitas   \n",
       "7        8   69.1456    160        1.60    Male        27.01      obesitas   \n",
       "8        9   39.3750    150        1.50  Female        17.50  under weight   \n",
       "9       10   40.4775    150        1.50  Female        17.99  under weight   \n",
       "10      11   40.5000    150        1.50  Female        18.00        normal   \n",
       "11      12   56.2275    150        1.50  Female        24.99        normal   \n",
       "12      13   56.2500    150        1.50  Female        25.00   over weight   \n",
       "13      14   60.7500    150        1.50  Female        27.00   over weight   \n",
       "14      15   60.7725    150        1.50  Female        27.01      obesitas   \n",
       "15      16   61.8750    150        1.50  Female        27.50      obesitas   \n",
       "16      17   96.0000    174        1.74    Male        31.71      obesitas   \n",
       "17      18   87.0000    189        1.89    Male        24.36   over weight   \n",
       "18      19  110.0000    185        1.85  Female        32.14      obesitas   \n",
       "19      20  104.0000    195        1.95  Female        27.35      obesitas   \n",
       "20      21   61.0000    149        1.49    Male        27.48      obesitas   \n",
       "21      22  104.0000    189        1.89    Male        29.11      obesitas   \n",
       "22      23   92.0000    147        1.47    Male        42.57      obesitas   \n",
       "23      24  111.0000    154        1.54    Male        46.80      obesitas   \n",
       "24      25   90.0000    174        1.74    Male        29.73      obesitas   \n",
       "25      26  103.0000    169        1.69  Female        36.06      obesitas   \n",
       "26      27   81.0000    195        1.95    Male        21.30        normal   \n",
       "27      28   80.0000    159        1.59  Female        31.64      obesitas   \n",
       "28      29  101.0000    192        1.92  Female        27.40      obesitas   \n",
       "29      30   51.0000    155        1.55    Male        21.23        normal   \n",
       "..     ...       ...    ...         ...     ...          ...           ...   \n",
       "486    488  142.0000    147        1.47    Male        65.71      obesitas   \n",
       "487    489  112.0000    154        1.54    Male        47.23      obesitas   \n",
       "488    490   65.0000    178        1.78  Female        20.52        normal   \n",
       "489    491  153.0000    195        1.95    Male        40.24      obesitas   \n",
       "490    492   79.0000    167        1.67  Female        28.33      obesitas   \n",
       "491    493  131.0000    183        1.83    Male        39.12      obesitas   \n",
       "492    494  142.0000    164        1.64  Female        52.80      obesitas   \n",
       "493    495   64.0000    167        1.67    Male        22.95        normal   \n",
       "494    496   55.0000    151        1.51  Female        24.12   over weight   \n",
       "495    497  107.0000    147        1.47  Female        49.52      obesitas   \n",
       "496    498  115.0000    155        1.55  Female        47.87      obesitas   \n",
       "497    499  108.0000    172        1.72  Female        36.51      obesitas   \n",
       "498    500   86.0000    142        1.42  Female        42.65      obesitas   \n",
       "499    501   85.0000    146        1.46    Male        39.88      obesitas   \n",
       "500    502  115.0000    188        1.88  Female        32.54      obesitas   \n",
       "501    503  111.0000    173        1.73    Male        37.09      obesitas   \n",
       "502    504  109.0000    160        1.60  Female        42.58      obesitas   \n",
       "503    505   80.0000    187        1.87    Male        22.88        normal   \n",
       "504    506  136.0000    198        1.98    Male        34.69      obesitas   \n",
       "505    507  150.0000    179        1.79  Female        46.82      obesitas   \n",
       "506    508   59.0000    164        1.64  Female        21.94        normal   \n",
       "507    509  147.0000    146        1.46  Female        68.96      obesitas   \n",
       "508    510   50.0000    198        1.98  Female        12.75  under weight   \n",
       "509    511   53.0000    170        1.70  Female        18.34        normal   \n",
       "510    512   98.0000    152        1.52    Male        42.42      obesitas   \n",
       "511    513  153.0000    150        1.50  Female        68.00      obesitas   \n",
       "512    514  121.0000    184        1.84  Female        35.74      obesitas   \n",
       "513    515  136.0000    141        1.41  Female        68.41      obesitas   \n",
       "514    516   95.0000    150        1.50    Male        42.22      obesitas   \n",
       "515    517  131.0000    173        1.73    Male        43.77      obesitas   \n",
       "\n",
       "     lari   normal  obesitas  over weight  under weight  \n",
       "0        0       0         0            0             1  \n",
       "1        0       0         0            0             1  \n",
       "2       30       1         0            0             0  \n",
       "3       30       1         0            0             0  \n",
       "4       60       0         0            1             0  \n",
       "5       60       0         0            1             0  \n",
       "6       90       0         1            0             0  \n",
       "7       90       0         1            0             0  \n",
       "8        0       0         0            0             1  \n",
       "9        0       0         0            0             1  \n",
       "10      30       1         0            0             0  \n",
       "11      30       1         0            0             0  \n",
       "12      60       0         0            1             0  \n",
       "13      60       0         0            1             0  \n",
       "14      90       0         1            0             0  \n",
       "15      90       0         1            0             0  \n",
       "16      90       0         1            0             0  \n",
       "17      60       0         0            1             0  \n",
       "18      90       0         1            0             0  \n",
       "19      90       0         1            0             0  \n",
       "20      90       0         1            0             0  \n",
       "21      90       0         1            0             0  \n",
       "22      90       0         1            0             0  \n",
       "23      90       0         1            0             0  \n",
       "24      90       0         1            0             0  \n",
       "25      90       0         1            0             0  \n",
       "26      30       1         0            0             0  \n",
       "27      90       0         1            0             0  \n",
       "28      90       0         1            0             0  \n",
       "29      30       1         0            0             0  \n",
       "..     ...     ...       ...          ...           ...  \n",
       "486     90       0         1            0             0  \n",
       "487     90       0         1            0             0  \n",
       "488     30       1         0            0             0  \n",
       "489     90       0         1            0             0  \n",
       "490     90       0         1            0             0  \n",
       "491     90       0         1            0             0  \n",
       "492     90       0         1            0             0  \n",
       "493     30       1         0            0             0  \n",
       "494     60       0         0            1             0  \n",
       "495     90       0         1            0             0  \n",
       "496     90       0         1            0             0  \n",
       "497     90       0         1            0             0  \n",
       "498     90       0         1            0             0  \n",
       "499     90       0         1            0             0  \n",
       "500     90       0         1            0             0  \n",
       "501     90       0         1            0             0  \n",
       "502     90       0         1            0             0  \n",
       "503     30       1         0            0             0  \n",
       "504     90       0         1            0             0  \n",
       "505     90       0         1            0             0  \n",
       "506     30       1         0            0             0  \n",
       "507     90       0         1            0             0  \n",
       "508      0       0         0            0             1  \n",
       "509     30       1         0            0             0  \n",
       "510     90       0         1            0             0  \n",
       "511     90       0         1            0             0  \n",
       "512     90       0         1            0             0  \n",
       "513     90       0         1            0             0  \n",
       "514     90       0         1            0             0  \n",
       "515     90       0         1            0             0  \n",
       "\n",
       "[516 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(file.gender)\n",
    "file1=pd.concat([file1,dummies],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=file1.drop(['no id','kesimpulan','tinggi (m)','gender','Female'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>berat ideal</th>\n",
       "      <th>lari</th>\n",
       "      <th>normal</th>\n",
       "      <th>obesitas</th>\n",
       "      <th>over weight</th>\n",
       "      <th>under weight</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>17.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>22.90</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>23.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     berat  tingg  berat ideal  lari   normal  obesitas  over weight  \\\n",
       "0  42.2400    160        16.50      0       0         0            0   \n",
       "1  43.4944    160        16.99      0       0         0            0   \n",
       "2  43.5200    160        17.00     30       1         0            0   \n",
       "3  58.6240    160        22.90     30       1         0            0   \n",
       "4  58.8800    160        23.00     60       0         0            1   \n",
       "\n",
       "   under weight  Male  \n",
       "0             1     1  \n",
       "1             1     1  \n",
       "2             0     1  \n",
       "3             0     1  \n",
       "4             0     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.columns = ['berat','tingg','berat ideal',\n",
    "                     'lari','normal','obesitas','over weight','under weight','gender']\n",
    "cols = file1.columns.tolist()\n",
    "cols=['berat','tingg','gender','berat ideal','lari','normal','obesitas','over weight','under weight']\n",
    "final=file1[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "      <th>lari</th>\n",
       "      <th>normal</th>\n",
       "      <th>obesitas</th>\n",
       "      <th>over weight</th>\n",
       "      <th>under weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>22.90</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.0944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>26.99</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.1200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.1456</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.01</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.3750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.4775</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.5000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.2275</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>24.99</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56.2500</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60.7500</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60.7725</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.01</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>61.8750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.50</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>31.71</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>87.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>24.36</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>110.0000</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>32.14</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>27.35</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>27.48</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>29.11</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>92.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>42.57</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>111.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>46.80</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>29.73</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>103.0000</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>36.06</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>81.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>21.30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101.0000</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>21.23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>142.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>112.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>47.23</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>65.0000</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>20.52</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>153.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>40.24</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>79.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>28.33</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>39.12</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>142.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>52.80</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>64.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>22.95</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>55.0000</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>24.12</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>107.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>49.52</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>115.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>47.87</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>108.0000</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>36.51</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>86.0000</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>42.65</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>85.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>39.88</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>115.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>32.54</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>111.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>37.09</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>109.0000</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>42.58</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>22.88</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>34.69</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>150.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>46.82</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>59.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>21.94</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>147.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>68.96</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>50.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>53.0000</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>18.34</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>98.0000</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>42.42</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>153.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>121.0000</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>35.74</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>68.41</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>95.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>42.22</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>43.77</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        berat  tingg  gender  berat ideal  lari  normal  obesitas  \\\n",
       "0     42.2400    160       1        16.50     0       0         0   \n",
       "1     43.4944    160       1        16.99     0       0         0   \n",
       "2     43.5200    160       1        17.00    30       1         0   \n",
       "3     58.6240    160       1        22.90    30       1         0   \n",
       "4     58.8800    160       1        23.00    60       0         0   \n",
       "5     69.0944    160       1        26.99    60       0         0   \n",
       "6     69.1200    160       1        27.00    90       0         1   \n",
       "7     69.1456    160       1        27.01    90       0         1   \n",
       "8     39.3750    150       0        17.50     0       0         0   \n",
       "9     40.4775    150       0        17.99     0       0         0   \n",
       "10    40.5000    150       0        18.00    30       1         0   \n",
       "11    56.2275    150       0        24.99    30       1         0   \n",
       "12    56.2500    150       0        25.00    60       0         0   \n",
       "13    60.7500    150       0        27.00    60       0         0   \n",
       "14    60.7725    150       0        27.01    90       0         1   \n",
       "15    61.8750    150       0        27.50    90       0         1   \n",
       "16    96.0000    174       1        31.71    90       0         1   \n",
       "17    87.0000    189       1        24.36    60       0         0   \n",
       "18   110.0000    185       0        32.14    90       0         1   \n",
       "19   104.0000    195       0        27.35    90       0         1   \n",
       "20    61.0000    149       1        27.48    90       0         1   \n",
       "21   104.0000    189       1        29.11    90       0         1   \n",
       "22    92.0000    147       1        42.57    90       0         1   \n",
       "23   111.0000    154       1        46.80    90       0         1   \n",
       "24    90.0000    174       1        29.73    90       0         1   \n",
       "25   103.0000    169       0        36.06    90       0         1   \n",
       "26    81.0000    195       1        21.30    30       1         0   \n",
       "27    80.0000    159       0        31.64    90       0         1   \n",
       "28   101.0000    192       0        27.40    90       0         1   \n",
       "29    51.0000    155       1        21.23    30       1         0   \n",
       "..        ...    ...     ...          ...   ...     ...       ...   \n",
       "486  142.0000    147       1        65.71    90       0         1   \n",
       "487  112.0000    154       1        47.23    90       0         1   \n",
       "488   65.0000    178       0        20.52    30       1         0   \n",
       "489  153.0000    195       1        40.24    90       0         1   \n",
       "490   79.0000    167       0        28.33    90       0         1   \n",
       "491  131.0000    183       1        39.12    90       0         1   \n",
       "492  142.0000    164       0        52.80    90       0         1   \n",
       "493   64.0000    167       1        22.95    30       1         0   \n",
       "494   55.0000    151       0        24.12    60       0         0   \n",
       "495  107.0000    147       0        49.52    90       0         1   \n",
       "496  115.0000    155       0        47.87    90       0         1   \n",
       "497  108.0000    172       0        36.51    90       0         1   \n",
       "498   86.0000    142       0        42.65    90       0         1   \n",
       "499   85.0000    146       1        39.88    90       0         1   \n",
       "500  115.0000    188       0        32.54    90       0         1   \n",
       "501  111.0000    173       1        37.09    90       0         1   \n",
       "502  109.0000    160       0        42.58    90       0         1   \n",
       "503   80.0000    187       1        22.88    30       1         0   \n",
       "504  136.0000    198       1        34.69    90       0         1   \n",
       "505  150.0000    179       0        46.82    90       0         1   \n",
       "506   59.0000    164       0        21.94    30       1         0   \n",
       "507  147.0000    146       0        68.96    90       0         1   \n",
       "508   50.0000    198       0        12.75     0       0         0   \n",
       "509   53.0000    170       0        18.34    30       1         0   \n",
       "510   98.0000    152       1        42.42    90       0         1   \n",
       "511  153.0000    150       0        68.00    90       0         1   \n",
       "512  121.0000    184       0        35.74    90       0         1   \n",
       "513  136.0000    141       0        68.41    90       0         1   \n",
       "514   95.0000    150       1        42.22    90       0         1   \n",
       "515  131.0000    173       1        43.77    90       0         1   \n",
       "\n",
       "     over weight  under weight  \n",
       "0              0             1  \n",
       "1              0             1  \n",
       "2              0             0  \n",
       "3              0             0  \n",
       "4              1             0  \n",
       "5              1             0  \n",
       "6              0             0  \n",
       "7              0             0  \n",
       "8              0             1  \n",
       "9              0             1  \n",
       "10             0             0  \n",
       "11             0             0  \n",
       "12             1             0  \n",
       "13             1             0  \n",
       "14             0             0  \n",
       "15             0             0  \n",
       "16             0             0  \n",
       "17             1             0  \n",
       "18             0             0  \n",
       "19             0             0  \n",
       "20             0             0  \n",
       "21             0             0  \n",
       "22             0             0  \n",
       "23             0             0  \n",
       "24             0             0  \n",
       "25             0             0  \n",
       "26             0             0  \n",
       "27             0             0  \n",
       "28             0             0  \n",
       "29             0             0  \n",
       "..           ...           ...  \n",
       "486            0             0  \n",
       "487            0             0  \n",
       "488            0             0  \n",
       "489            0             0  \n",
       "490            0             0  \n",
       "491            0             0  \n",
       "492            0             0  \n",
       "493            0             0  \n",
       "494            1             0  \n",
       "495            0             0  \n",
       "496            0             0  \n",
       "497            0             0  \n",
       "498            0             0  \n",
       "499            0             0  \n",
       "500            0             0  \n",
       "501            0             0  \n",
       "502            0             0  \n",
       "503            0             0  \n",
       "504            0             0  \n",
       "505            0             0  \n",
       "506            0             0  \n",
       "507            0             0  \n",
       "508            0             1  \n",
       "509            0             0  \n",
       "510            0             0  \n",
       "511            0             0  \n",
       "512            0             0  \n",
       "513            0             0  \n",
       "514            0             0  \n",
       "515            0             0  \n",
       "\n",
       "[516 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "      <th>lari</th>\n",
       "      <th>normal</th>\n",
       "      <th>obesitas</th>\n",
       "      <th>over weight</th>\n",
       "      <th>under weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>22.90</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     berat  tingg  gender  berat ideal  lari  normal  obesitas  over weight  \\\n",
       "0  42.2400    160       1        16.50     0       0         0            0   \n",
       "1  43.4944    160       1        16.99     0       0         0            0   \n",
       "2  43.5200    160       1        17.00    30       1         0            0   \n",
       "3  58.6240    160       1        22.90    30       1         0            0   \n",
       "4  58.8800    160       1        23.00    60       0         0            1   \n",
       "\n",
       "   under weight  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ms=MinMaxScaler()\n",
    "#ms.fit(final.iloc[:,:5])\n",
    "#final=ms.transform(final.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "      <th>lari</th>\n",
       "      <th>normal</th>\n",
       "      <th>obesitas</th>\n",
       "      <th>over weight</th>\n",
       "      <th>under weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>22.90</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     berat  tingg  gender  berat ideal  lari  normal  obesitas  over weight  \\\n",
       "0  42.2400    160       1        16.50     0       0         0            0   \n",
       "1  43.4944    160       1        16.99     0       0         0            0   \n",
       "2  43.5200    160       1        17.00    30       1         0            0   \n",
       "3  58.6240    160       1        22.90    30       1         0            0   \n",
       "4  58.8800    160       1        23.00    60       0         0            1   \n",
       "\n",
       "   under weight  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final[:6,:]\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=final[:,4]\n",
    "y=final.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2    30\n",
       "3    30\n",
       "4    60\n",
       "Name: lari, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.2400</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.4944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.5200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.6240</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>22.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.8800</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.0944</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>26.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.1200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.1456</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.3750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.4775</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.5000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.2275</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56.2500</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60.7500</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60.7725</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>61.8750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>31.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>87.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>24.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>110.0000</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>32.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>27.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>27.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>29.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>92.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>42.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>111.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>46.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90.0000</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>29.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>103.0000</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>36.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>81.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>31.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101.0000</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>27.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>21.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>142.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>112.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>47.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>65.0000</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>20.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>153.0000</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>79.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>28.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>39.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>142.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>52.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>64.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>55.0000</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>24.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>107.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>49.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>115.0000</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>47.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>108.0000</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>36.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>86.0000</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>42.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>85.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>39.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>115.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>32.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>111.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>37.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>109.0000</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>42.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>22.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>34.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>150.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>46.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>59.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>147.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>68.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>50.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>53.0000</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>98.0000</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>42.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>153.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>121.0000</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>35.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>68.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>95.0000</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>42.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>43.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        berat  tingg  gender  berat ideal\n",
       "0     42.2400    160       1        16.50\n",
       "1     43.4944    160       1        16.99\n",
       "2     43.5200    160       1        17.00\n",
       "3     58.6240    160       1        22.90\n",
       "4     58.8800    160       1        23.00\n",
       "5     69.0944    160       1        26.99\n",
       "6     69.1200    160       1        27.00\n",
       "7     69.1456    160       1        27.01\n",
       "8     39.3750    150       0        17.50\n",
       "9     40.4775    150       0        17.99\n",
       "10    40.5000    150       0        18.00\n",
       "11    56.2275    150       0        24.99\n",
       "12    56.2500    150       0        25.00\n",
       "13    60.7500    150       0        27.00\n",
       "14    60.7725    150       0        27.01\n",
       "15    61.8750    150       0        27.50\n",
       "16    96.0000    174       1        31.71\n",
       "17    87.0000    189       1        24.36\n",
       "18   110.0000    185       0        32.14\n",
       "19   104.0000    195       0        27.35\n",
       "20    61.0000    149       1        27.48\n",
       "21   104.0000    189       1        29.11\n",
       "22    92.0000    147       1        42.57\n",
       "23   111.0000    154       1        46.80\n",
       "24    90.0000    174       1        29.73\n",
       "25   103.0000    169       0        36.06\n",
       "26    81.0000    195       1        21.30\n",
       "27    80.0000    159       0        31.64\n",
       "28   101.0000    192       0        27.40\n",
       "29    51.0000    155       1        21.23\n",
       "..        ...    ...     ...          ...\n",
       "486  142.0000    147       1        65.71\n",
       "487  112.0000    154       1        47.23\n",
       "488   65.0000    178       0        20.52\n",
       "489  153.0000    195       1        40.24\n",
       "490   79.0000    167       0        28.33\n",
       "491  131.0000    183       1        39.12\n",
       "492  142.0000    164       0        52.80\n",
       "493   64.0000    167       1        22.95\n",
       "494   55.0000    151       0        24.12\n",
       "495  107.0000    147       0        49.52\n",
       "496  115.0000    155       0        47.87\n",
       "497  108.0000    172       0        36.51\n",
       "498   86.0000    142       0        42.65\n",
       "499   85.0000    146       1        39.88\n",
       "500  115.0000    188       0        32.54\n",
       "501  111.0000    173       1        37.09\n",
       "502  109.0000    160       0        42.58\n",
       "503   80.0000    187       1        22.88\n",
       "504  136.0000    198       1        34.69\n",
       "505  150.0000    179       0        46.82\n",
       "506   59.0000    164       0        21.94\n",
       "507  147.0000    146       0        68.96\n",
       "508   50.0000    198       0        12.75\n",
       "509   53.0000    170       0        18.34\n",
       "510   98.0000    152       1        42.42\n",
       "511  153.0000    150       0        68.00\n",
       "512  121.0000    184       0        35.74\n",
       "513  136.0000    141       0        68.41\n",
       "514   95.0000    150       1        42.22\n",
       "515  131.0000    173       1        43.77\n",
       "\n",
       "[516 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=final[:,:4]\n",
    "x=final.iloc[:,:4]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berat</th>\n",
       "      <th>tingg</th>\n",
       "      <th>gender</th>\n",
       "      <th>berat ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>41.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>141.0000</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>67.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>96.0000</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>26.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>89.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>25.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>103.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>32.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.1200</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>154.0000</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>59.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>155.0000</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>59.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>74.0000</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>28.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>83.0000</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>30.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>157.0000</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>46.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69.1456</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>27.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>143.0000</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>43.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.3750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>148.0000</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>52.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>133.0000</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>56.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>85.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>30.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>34.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>160.0000</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>56.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>104.0000</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>31.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>28.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>151.0000</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>54.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>51.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>126.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>46.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>106.0000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>32.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>81.0000</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>25.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>118.0000</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>45.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>43.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>70.0000</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>141.0000</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>61.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>117.0000</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>37.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>123.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>34.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>101.0000</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>47.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>50.0000</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>66.0000</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>26.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>89.0000</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>34.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>92.0000</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>31.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>135.0000</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>66.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>103.0000</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>36.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>115.0000</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>40.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>111.0000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>33.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>59.0000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>21.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>102.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>29.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>53.0000</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>139.0000</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>40.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>142.0000</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>94.0000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>28.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>92.0000</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>26.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>120.0000</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>47.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>80.0000</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>128.0000</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>36.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>116.0000</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>30.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>117.0000</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>36.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>114.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>35.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>70.0000</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>25.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>131.0000</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>49.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.4775</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>83.0000</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>102.0000</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>35.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        berat  tingg  gender  berat ideal\n",
       "276  104.0000    159       1        41.14\n",
       "479  141.0000    145       0        67.06\n",
       "224   96.0000    191       1        26.32\n",
       "71    89.0000    187       0        25.45\n",
       "171  103.0000    179       0        32.15\n",
       "6     69.1200    160       1        27.00\n",
       "429  154.0000    161       0        59.41\n",
       "118  155.0000    161       1        59.80\n",
       "196   74.0000    162       0        28.20\n",
       "309   83.0000    165       0        30.49\n",
       "453  157.0000    184       1        46.37\n",
       "381   80.0000    141       1        40.24\n",
       "7     69.1456    160       1        27.01\n",
       "179  143.0000    182       0        43.17\n",
       "8     39.3750    150       0        17.50\n",
       "284  148.0000    168       1        52.44\n",
       "452  133.0000    153       0        56.82\n",
       "157   85.0000    167       0        30.48\n",
       "504  136.0000    198       1        34.69\n",
       "173  160.0000    168       1        56.69\n",
       "219  104.0000    182       1        31.40\n",
       "195  100.0000    188       1        28.29\n",
       "188  151.0000    167       1        54.14\n",
       "49   131.0000    160       0        51.17\n",
       "353  126.0000    164       0        46.85\n",
       "124  106.0000    181       0        32.36\n",
       "249   81.0000    177       0        25.85\n",
       "59   118.0000    161       1        45.52\n",
       "515  131.0000    173       1        43.77\n",
       "407   70.0000    180       0        21.60\n",
       "..        ...    ...     ...          ...\n",
       "335  141.0000    152       1        61.03\n",
       "197  117.0000    177       1        37.35\n",
       "243  123.0000    188       1        34.80\n",
       "464  101.0000    146       0        47.38\n",
       "115   50.0000    190       0        13.85\n",
       "404   66.0000    157       0        26.78\n",
       "265   89.0000    161       1        34.34\n",
       "72    92.0000    172       1        31.10\n",
       "333  135.0000    142       1        66.95\n",
       "25   103.0000    169       0        36.06\n",
       "165  115.0000    168       0        40.75\n",
       "337  111.0000    181       0        33.88\n",
       "506   59.0000    164       0        21.94\n",
       "174  102.0000    187       0        29.17\n",
       "509   53.0000    170       0        18.34\n",
       "39   139.0000    185       1        40.61\n",
       "486  142.0000    147       1        65.71\n",
       "193   94.0000    181       0        28.69\n",
       "314   92.0000    187       0        26.31\n",
       "396  120.0000    159       1        47.47\n",
       "88    80.0000    141       1        40.24\n",
       "472  128.0000    188       0        36.22\n",
       "70   116.0000    196       1        30.20\n",
       "87   117.0000    178       1        36.93\n",
       "292  114.0000    179       0        35.58\n",
       "242   70.0000    166       1        25.40\n",
       "277  131.0000    163       1        49.31\n",
       "9     40.4775    150       0        17.99\n",
       "359   83.0000    179       1        25.90\n",
       "192  102.0000    170       0        35.29\n",
       "\n",
       "[412 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0,:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.optimizers import adam\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alpha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alpha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alpha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(8,input_shape=(4,)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(4,))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(1,))\n",
    "# model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_shape=(4,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16,))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32,))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16,))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(8,))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dense(1,))\n",
    "# model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = adam(lr=1e-3, decay=1e-3 /200)\n",
    "opt=adam(lr=1e-3)\n",
    "#model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['mean_absolute_error'])\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412 samples, validate on 104 samples\n",
      "Epoch 1/1000\n",
      "412/412 [==============================] - 1s 2ms/step - loss: 6228.4497 - acc: 0.0000e+00 - val_loss: 6645.2764 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 6209.1519 - acc: 0.0000e+00 - val_loss: 6626.7261 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 6189.2754 - acc: 0.0000e+00 - val_loss: 6607.2183 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 6168.4395 - acc: 0.0000e+00 - val_loss: 6586.6636 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 6146.6431 - acc: 0.0000e+00 - val_loss: 6565.0645 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 6123.8032 - acc: 0.0000e+00 - val_loss: 6542.4253 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 6099.8403 - acc: 0.0000e+00 - val_loss: 6519.1372 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 6075.2891 - acc: 0.0000e+00 - val_loss: 6494.1201 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 6049.0400 - acc: 0.0000e+00 - val_loss: 6467.7729 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 6021.5049 - acc: 0.0000e+00 - val_loss: 6439.9194 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 5992.5830 - acc: 0.0000e+00 - val_loss: 6410.5132 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 5962.1543 - acc: 0.0000e+00 - val_loss: 6379.3428 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 5930.0054 - acc: 0.0000e+00 - val_loss: 6346.4722 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 5896.0698 - acc: 0.0000e+00 - val_loss: 6311.7598 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5860.3931 - acc: 0.0000e+00 - val_loss: 6275.1455 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 5822.9917 - acc: 0.0000e+00 - val_loss: 6236.4810 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 5783.5884 - acc: 0.0000e+00 - val_loss: 6195.8071 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5742.2305 - acc: 0.0000e+00 - val_loss: 6153.0566 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5698.7231 - acc: 0.0000e+00 - val_loss: 6108.0420 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 5652.9648 - acc: 0.0000e+00 - val_loss: 6060.4434 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5604.5845 - acc: 0.0000e+00 - val_loss: 6009.4185 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 5553.7173 - acc: 0.0000e+00 - val_loss: 5955.4951 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5500.2793 - acc: 0.0000e+00 - val_loss: 5898.9146 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 5444.2949 - acc: 0.0000e+00 - val_loss: 5839.5806 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5385.6177 - acc: 0.0000e+00 - val_loss: 5777.3613 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 5324.1919 - acc: 0.0000e+00 - val_loss: 5711.7065 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 5259.8350 - acc: 0.0000e+00 - val_loss: 5642.7104 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 5192.7100 - acc: 0.0000e+00 - val_loss: 5570.4160 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 5122.7031 - acc: 0.0000e+00 - val_loss: 5494.7866 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 5049.7046 - acc: 0.0000e+00 - val_loss: 5415.5493 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 4973.4321 - acc: 0.0000e+00 - val_loss: 5332.9849 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "412/412 [==============================] - 0s 32us/step - loss: 4894.0405 - acc: 0.0000e+00 - val_loss: 5247.6699 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 4812.2710 - acc: 0.0121 - val_loss: 5159.2319 - val_acc: 0.0096\n",
      "Epoch 34/1000\n",
      "412/412 [==============================] - 0s 32us/step - loss: 4727.6104 - acc: 0.0097 - val_loss: 5067.1323 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 4640.0371 - acc: 0.0146 - val_loss: 4971.2036 - val_acc: 0.0192\n",
      "Epoch 36/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 4549.8086 - acc: 0.0316 - val_loss: 4871.9292 - val_acc: 0.0288\n",
      "Epoch 37/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 4456.8994 - acc: 0.0218 - val_loss: 4769.5371 - val_acc: 0.0096\n",
      "Epoch 38/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 4361.3081 - acc: 0.0097 - val_loss: 4664.2627 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 4263.4609 - acc: 0.0000e+00 - val_loss: 4555.0562 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 4162.0166 - acc: 0.0000e+00 - val_loss: 4444.0181 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 4059.6990 - acc: 0.0000e+00 - val_loss: 4331.0020 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 3955.6616 - acc: 0.0000e+00 - val_loss: 4216.4370 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 3849.9902 - acc: 0.0000e+00 - val_loss: 4100.6973 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 3743.1067 - acc: 0.0000e+00 - val_loss: 3984.2920 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 3636.2310 - acc: 0.0000e+00 - val_loss: 3867.4561 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 3529.5049 - acc: 0.0000e+00 - val_loss: 3750.3110 - val_acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 3423.8096 - acc: 0.0000e+00 - val_loss: 3634.2537 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 3320.1611 - acc: 0.0000e+00 - val_loss: 3519.2444 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 3219.2285 - acc: 0.0000e+00 - val_loss: 3405.6938 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 3121.7524 - acc: 0.0073 - val_loss: 3295.1455 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 3029.0474 - acc: 0.0049 - val_loss: 3188.6912 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2941.4751 - acc: 0.0073 - val_loss: 3087.3823 - val_acc: 0.0192\n",
      "Epoch 53/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 2859.5796 - acc: 0.0073 - val_loss: 2991.9111 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 2784.2087 - acc: 0.0000e+00 - val_loss: 2903.5205 - val_acc: 0.0096\n",
      "Epoch 55/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2716.7046 - acc: 0.0000e+00 - val_loss: 2822.0063 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 2656.3962 - acc: 0.0049 - val_loss: 2747.6060 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2603.3220 - acc: 0.0000e+00 - val_loss: 2681.1501 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 2558.2190 - acc: 0.0000e+00 - val_loss: 2622.5403 - val_acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 2519.6863 - acc: 0.0024 - val_loss: 2571.3643 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 2486.8611 - acc: 0.0000e+00 - val_loss: 2525.8811 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2458.4705 - acc: 0.0000e+00 - val_loss: 2485.6289 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2432.9653 - acc: 0.0000e+00 - val_loss: 2449.2034 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2408.5913 - acc: 0.0000e+00 - val_loss: 2412.5596 - val_acc: 0.0096\n",
      "Epoch 64/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2383.3848 - acc: 0.0024 - val_loss: 2376.6606 - val_acc: 0.0096\n",
      "Epoch 65/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2356.4285 - acc: 0.0000e+00 - val_loss: 2341.4182 - val_acc: 0.0192\n",
      "Epoch 66/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 2326.2571 - acc: 0.0049 - val_loss: 2307.3940 - val_acc: 0.0096\n",
      "Epoch 67/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2294.0210 - acc: 0.0073 - val_loss: 2273.6714 - val_acc: 0.0096\n",
      "Epoch 68/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2260.6514 - acc: 0.0073 - val_loss: 2239.6052 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 2225.1975 - acc: 0.0073 - val_loss: 2206.4319 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 2188.8960 - acc: 0.0073 - val_loss: 2174.9783 - val_acc: 0.0096\n",
      "Epoch 71/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 2153.5735 - acc: 0.0073 - val_loss: 2145.9807 - val_acc: 0.0192\n",
      "Epoch 72/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 2121.0479 - acc: 0.0049 - val_loss: 2120.0574 - val_acc: 0.0192\n",
      "Epoch 73/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 2090.6660 - acc: 0.0000e+00 - val_loss: 2095.4463 - val_acc: 0.0096\n",
      "Epoch 74/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 2061.8623 - acc: 0.0049 - val_loss: 2073.1606 - val_acc: 0.0096\n",
      "Epoch 75/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 2035.1062 - acc: 0.0073 - val_loss: 2052.6506 - val_acc: 0.0096\n",
      "Epoch 76/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 2010.2152 - acc: 0.0024 - val_loss: 2033.0126 - val_acc: 0.0192\n",
      "Epoch 77/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 1986.6342 - acc: 0.0049 - val_loss: 2013.8678 - val_acc: 0.0096\n",
      "Epoch 78/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1964.2156 - acc: 0.0024 - val_loss: 1994.6661 - val_acc: 0.0096\n",
      "Epoch 79/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1942.6232 - acc: 0.0049 - val_loss: 1975.1179 - val_acc: 0.0096\n",
      "Epoch 80/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 1921.4065 - acc: 0.0073 - val_loss: 1954.9669 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1900.2894 - acc: 0.0024 - val_loss: 1933.8575 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1879.0306 - acc: 0.0000e+00 - val_loss: 1912.0177 - val_acc: 0.0192\n",
      "Epoch 83/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1857.7727 - acc: 0.0000e+00 - val_loss: 1889.2064 - val_acc: 0.0192\n",
      "Epoch 84/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1836.2382 - acc: 0.0000e+00 - val_loss: 1865.4219 - val_acc: 0.0192\n",
      "Epoch 85/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1814.4071 - acc: 0.0000e+00 - val_loss: 1840.7683 - val_acc: 0.0288\n",
      "Epoch 86/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1792.4302 - acc: 0.0024 - val_loss: 1815.5126 - val_acc: 0.0192\n",
      "Epoch 87/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1770.4536 - acc: 0.0049 - val_loss: 1789.9402 - val_acc: 0.0192\n",
      "Epoch 88/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1748.5870 - acc: 0.0049 - val_loss: 1764.2759 - val_acc: 0.0096\n",
      "Epoch 89/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1726.9663 - acc: 0.0049 - val_loss: 1738.7860 - val_acc: 0.0096\n",
      "Epoch 90/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 1705.6975 - acc: 0.0024 - val_loss: 1713.6874 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1684.8662 - acc: 0.0024 - val_loss: 1689.2832 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1664.6041 - acc: 0.0073 - val_loss: 1665.6854 - val_acc: 0.0288\n",
      "Epoch 93/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 1644.7877 - acc: 0.0097 - val_loss: 1642.7377 - val_acc: 0.0288\n",
      "Epoch 94/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1625.3226 - acc: 0.0146 - val_loss: 1620.4685 - val_acc: 0.0096\n",
      "Epoch 95/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1606.0179 - acc: 0.0121 - val_loss: 1598.8378 - val_acc: 0.0096\n",
      "Epoch 96/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1586.8069 - acc: 0.0097 - val_loss: 1577.7715 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1567.6189 - acc: 0.0121 - val_loss: 1557.3397 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 1548.4460 - acc: 0.0073 - val_loss: 1537.5565 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1529.2562 - acc: 0.0073 - val_loss: 1518.5320 - val_acc: 0.0096\n",
      "Epoch 100/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1510.4640 - acc: 0.0049 - val_loss: 1500.4441 - val_acc: 0.0096\n",
      "Epoch 101/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 1492.3865 - acc: 0.0024 - val_loss: 1482.7812 - val_acc: 0.0096\n",
      "Epoch 102/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1474.5051 - acc: 0.0049 - val_loss: 1465.5120 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 1456.7843 - acc: 0.0097 - val_loss: 1448.4506 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1439.1661 - acc: 0.0121 - val_loss: 1431.4552 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1421.7495 - acc: 0.0146 - val_loss: 1414.3586 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 1404.3574 - acc: 0.0121 - val_loss: 1397.0312 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1386.9248 - acc: 0.0097 - val_loss: 1379.4797 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1369.4800 - acc: 0.0097 - val_loss: 1361.7795 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 1352.2106 - acc: 0.0073 - val_loss: 1344.0358 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1335.0221 - acc: 0.0121 - val_loss: 1326.2183 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "412/412 [==============================] - 0s 32us/step - loss: 1317.8694 - acc: 0.0121 - val_loss: 1308.3391 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1300.7537 - acc: 0.0049 - val_loss: 1290.4662 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 1283.7086 - acc: 0.0073 - val_loss: 1272.6404 - val_acc: 0.0096\n",
      "Epoch 114/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 1266.7515 - acc: 0.0073 - val_loss: 1254.8927 - val_acc: 0.0096\n",
      "Epoch 115/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 1249.9487 - acc: 0.0097 - val_loss: 1237.5123 - val_acc: 0.0096\n",
      "Epoch 116/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 1233.4105 - acc: 0.0097 - val_loss: 1220.5411 - val_acc: 0.0096\n",
      "Epoch 117/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1217.1008 - acc: 0.0146 - val_loss: 1203.8220 - val_acc: 0.0096\n",
      "Epoch 118/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1200.9077 - acc: 0.0170 - val_loss: 1187.3638 - val_acc: 0.0096\n",
      "Epoch 119/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1184.8151 - acc: 0.0170 - val_loss: 1171.1099 - val_acc: 0.0192\n",
      "Epoch 120/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1168.8203 - acc: 0.0194 - val_loss: 1155.0725 - val_acc: 0.0192\n",
      "Epoch 121/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1152.9551 - acc: 0.0194 - val_loss: 1139.2615 - val_acc: 0.0192\n",
      "Epoch 122/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1137.2135 - acc: 0.0097 - val_loss: 1123.6483 - val_acc: 0.0192\n",
      "Epoch 123/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 1121.5342 - acc: 0.0073 - val_loss: 1108.1359 - val_acc: 0.0192\n",
      "Epoch 124/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1105.9846 - acc: 0.0097 - val_loss: 1092.7583 - val_acc: 0.0096\n",
      "Epoch 125/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1090.6216 - acc: 0.0097 - val_loss: 1077.5060 - val_acc: 0.0096\n",
      "Epoch 126/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 1075.3656 - acc: 0.0049 - val_loss: 1062.1810 - val_acc: 0.0096\n",
      "Epoch 127/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 1060.3420 - acc: 0.0097 - val_loss: 1046.8953 - val_acc: 0.0096\n",
      "Epoch 128/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1046.0592 - acc: 0.0121 - val_loss: 1031.9667 - val_acc: 0.0096\n",
      "Epoch 129/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1032.1843 - acc: 0.0218 - val_loss: 1017.1794 - val_acc: 0.0192\n",
      "Epoch 130/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 1018.4213 - acc: 0.0243 - val_loss: 1002.7147 - val_acc: 0.0192\n",
      "Epoch 131/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 1005.0913 - acc: 0.0170 - val_loss: 988.6002 - val_acc: 0.0096\n",
      "Epoch 132/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 992.1684 - acc: 0.0146 - val_loss: 974.9711 - val_acc: 0.0096\n",
      "Epoch 133/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 979.4532 - acc: 0.0097 - val_loss: 961.7507 - val_acc: 0.0192\n",
      "Epoch 134/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 966.9088 - acc: 0.0049 - val_loss: 949.1332 - val_acc: 0.0288\n",
      "Epoch 135/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 954.5309 - acc: 0.0146 - val_loss: 936.9030 - val_acc: 0.0288\n",
      "Epoch 136/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 942.3390 - acc: 0.0170 - val_loss: 925.0309 - val_acc: 0.0096\n",
      "Epoch 137/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 930.2894 - acc: 0.0146 - val_loss: 913.5352 - val_acc: 0.0192\n",
      "Epoch 138/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 918.4156 - acc: 0.0097 - val_loss: 902.4493 - val_acc: 0.0192\n",
      "Epoch 139/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 906.8193 - acc: 0.0097 - val_loss: 891.7039 - val_acc: 0.0192\n",
      "Epoch 140/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 895.6111 - acc: 0.0049 - val_loss: 880.9073 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 884.4994 - acc: 0.0097 - val_loss: 869.9786 - val_acc: 0.0096\n",
      "Epoch 142/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 873.4438 - acc: 0.0146 - val_loss: 859.2545 - val_acc: 0.0481\n",
      "Epoch 143/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 862.6579 - acc: 0.0170 - val_loss: 848.9174 - val_acc: 0.0481\n",
      "Epoch 144/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 852.2057 - acc: 0.0194 - val_loss: 838.9220 - val_acc: 0.0288\n",
      "Epoch 145/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 841.9554 - acc: 0.0170 - val_loss: 829.3002 - val_acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 831.9152 - acc: 0.0170 - val_loss: 820.0670 - val_acc: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 822.0721 - acc: 0.0170 - val_loss: 811.1542 - val_acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 812.4370 - acc: 0.0146 - val_loss: 802.5481 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 803.1275 - acc: 0.0170 - val_loss: 794.0449 - val_acc: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 794.0626 - acc: 0.0121 - val_loss: 785.5468 - val_acc: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 785.1001 - acc: 0.0097 - val_loss: 777.0350 - val_acc: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 776.2320 - acc: 0.0121 - val_loss: 768.7928 - val_acc: 0.0096\n",
      "Epoch 153/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 767.6328 - acc: 0.0121 - val_loss: 760.8025 - val_acc: 0.0481\n",
      "Epoch 154/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 759.4018 - acc: 0.0097 - val_loss: 753.1418 - val_acc: 0.0385\n",
      "Epoch 155/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 751.4315 - acc: 0.0049 - val_loss: 745.8194 - val_acc: 0.0385\n",
      "Epoch 156/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 743.6202 - acc: 0.0073 - val_loss: 738.6895 - val_acc: 0.0385\n",
      "Epoch 157/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 736.0409 - acc: 0.0073 - val_loss: 731.8106 - val_acc: 0.0385\n",
      "Epoch 158/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 728.6974 - acc: 0.0073 - val_loss: 725.1497 - val_acc: 0.0385\n",
      "Epoch 159/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 721.5615 - acc: 0.0097 - val_loss: 718.6283 - val_acc: 0.0385\n",
      "Epoch 160/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 714.6319 - acc: 0.0073 - val_loss: 712.1918 - val_acc: 0.0288\n",
      "Epoch 161/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 707.8386 - acc: 0.0097 - val_loss: 705.8477 - val_acc: 0.0192\n",
      "Epoch 162/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 701.1600 - acc: 0.0121 - val_loss: 699.6169 - val_acc: 0.0192\n",
      "Epoch 163/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 694.5756 - acc: 0.0194 - val_loss: 693.5497 - val_acc: 0.0192\n",
      "Epoch 164/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 688.1634 - acc: 0.0170 - val_loss: 687.6528 - val_acc: 0.0096\n",
      "Epoch 165/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 681.9121 - acc: 0.0194 - val_loss: 681.9689 - val_acc: 0.0096\n",
      "Epoch 166/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 675.7403 - acc: 0.0146 - val_loss: 676.5818 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 669.6772 - acc: 0.0073 - val_loss: 671.3698 - val_acc: 0.0096\n",
      "Epoch 168/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 663.8141 - acc: 0.0073 - val_loss: 666.3173 - val_acc: 0.0096\n",
      "Epoch 169/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 658.1025 - acc: 0.0073 - val_loss: 661.4215 - val_acc: 0.0096\n",
      "Epoch 170/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 652.5820 - acc: 0.0049 - val_loss: 656.7122 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 647.2996 - acc: 0.0049 - val_loss: 652.0966 - val_acc: 0.0096\n",
      "Epoch 172/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 642.1576 - acc: 0.0049 - val_loss: 647.6048 - val_acc: 0.0096\n",
      "Epoch 173/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 637.1381 - acc: 0.0049 - val_loss: 643.2444 - val_acc: 0.0192\n",
      "Epoch 174/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 632.2482 - acc: 0.0024 - val_loss: 638.9886 - val_acc: 0.0192\n",
      "Epoch 175/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 627.5018 - acc: 0.0049 - val_loss: 634.8279 - val_acc: 0.0288\n",
      "Epoch 176/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 622.8921 - acc: 0.0049 - val_loss: 630.7628 - val_acc: 0.0192\n",
      "Epoch 177/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 618.3704 - acc: 0.0049 - val_loss: 626.7999 - val_acc: 0.0096\n",
      "Epoch 178/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 613.9683 - acc: 0.0049 - val_loss: 622.8967 - val_acc: 0.0096\n",
      "Epoch 179/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 609.6798 - acc: 0.0097 - val_loss: 618.9823 - val_acc: 0.0096\n",
      "Epoch 180/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 605.4857 - acc: 0.0146 - val_loss: 615.0853 - val_acc: 0.0096\n",
      "Epoch 181/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 601.3856 - acc: 0.0146 - val_loss: 611.2388 - val_acc: 0.0096\n",
      "Epoch 182/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 597.3766 - acc: 0.0097 - val_loss: 607.4469 - val_acc: 0.0096\n",
      "Epoch 183/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 593.4489 - acc: 0.0097 - val_loss: 603.7059 - val_acc: 0.0096\n",
      "Epoch 184/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 589.6002 - acc: 0.0097 - val_loss: 600.0349 - val_acc: 0.0096\n",
      "Epoch 185/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 585.8448 - acc: 0.0097 - val_loss: 596.4512 - val_acc: 0.0096\n",
      "Epoch 186/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 582.2145 - acc: 0.0121 - val_loss: 592.9525 - val_acc: 0.0096\n",
      "Epoch 187/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 578.6815 - acc: 0.0194 - val_loss: 589.5026 - val_acc: 0.0096\n",
      "Epoch 188/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 575.2462 - acc: 0.0194 - val_loss: 586.1181 - val_acc: 0.0096\n",
      "Epoch 189/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 571.9097 - acc: 0.0194 - val_loss: 582.8275 - val_acc: 0.0096\n",
      "Epoch 190/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 568.6491 - acc: 0.0194 - val_loss: 579.6198 - val_acc: 0.0096\n",
      "Epoch 191/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 565.4700 - acc: 0.0218 - val_loss: 576.4926 - val_acc: 0.0096\n",
      "Epoch 192/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 562.3707 - acc: 0.0194 - val_loss: 573.4402 - val_acc: 0.0096\n",
      "Epoch 193/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 559.3452 - acc: 0.0218 - val_loss: 570.4558 - val_acc: 0.0096\n",
      "Epoch 194/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 556.3799 - acc: 0.0194 - val_loss: 567.5931 - val_acc: 0.0096\n",
      "Epoch 195/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 553.4691 - acc: 0.0194 - val_loss: 564.8646 - val_acc: 0.0096\n",
      "Epoch 196/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 550.6183 - acc: 0.0218 - val_loss: 562.2740 - val_acc: 0.0096\n",
      "Epoch 197/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 547.8294 - acc: 0.0194 - val_loss: 559.6517 - val_acc: 0.0096\n",
      "Epoch 198/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 545.0782 - acc: 0.0170 - val_loss: 557.0326 - val_acc: 0.0096\n",
      "Epoch 199/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 542.3893 - acc: 0.0121 - val_loss: 554.4382 - val_acc: 0.0096\n",
      "Epoch 200/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 539.7502 - acc: 0.0121 - val_loss: 551.8666 - val_acc: 0.0096\n",
      "Epoch 201/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 537.1562 - acc: 0.0146 - val_loss: 549.3242 - val_acc: 0.0096\n",
      "Epoch 202/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 534.5928 - acc: 0.0146 - val_loss: 546.7949 - val_acc: 0.0096\n",
      "Epoch 203/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 532.0700 - acc: 0.0170 - val_loss: 544.3105 - val_acc: 0.0192\n",
      "Epoch 204/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 529.6135 - acc: 0.0194 - val_loss: 541.8930 - val_acc: 0.0192\n",
      "Epoch 205/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 527.2225 - acc: 0.0194 - val_loss: 539.4213 - val_acc: 0.0192\n",
      "Epoch 206/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 524.8888 - acc: 0.0170 - val_loss: 536.9164 - val_acc: 0.0192\n",
      "Epoch 207/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 522.6274 - acc: 0.0170 - val_loss: 534.4667 - val_acc: 0.0192\n",
      "Epoch 208/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 520.4097 - acc: 0.0146 - val_loss: 532.0367 - val_acc: 0.0192\n",
      "Epoch 209/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 518.2334 - acc: 0.0146 - val_loss: 529.5743 - val_acc: 0.0192\n",
      "Epoch 210/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 516.0954 - acc: 0.0170 - val_loss: 527.1438 - val_acc: 0.0192\n",
      "Epoch 211/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 514.0032 - acc: 0.0243 - val_loss: 524.7616 - val_acc: 0.0192\n",
      "Epoch 212/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 511.9364 - acc: 0.0267 - val_loss: 522.4579 - val_acc: 0.0192\n",
      "Epoch 213/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 509.8799 - acc: 0.0267 - val_loss: 520.2273 - val_acc: 0.0192\n",
      "Epoch 214/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 507.8498 - acc: 0.0291 - val_loss: 518.1016 - val_acc: 0.0192\n",
      "Epoch 215/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 505.8568 - acc: 0.0291 - val_loss: 516.0625 - val_acc: 0.0192\n",
      "Epoch 216/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 503.8962 - acc: 0.0243 - val_loss: 514.0903 - val_acc: 0.0192\n",
      "Epoch 217/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 501.9642 - acc: 0.0267 - val_loss: 512.0765 - val_acc: 0.0192\n",
      "Epoch 218/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 500.0594 - acc: 0.0243 - val_loss: 510.0612 - val_acc: 0.0192\n",
      "Epoch 219/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 498.1944 - acc: 0.0218 - val_loss: 508.0703 - val_acc: 0.0192\n",
      "Epoch 220/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 496.3250 - acc: 0.0243 - val_loss: 506.1213 - val_acc: 0.0192\n",
      "Epoch 221/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 494.4411 - acc: 0.0243 - val_loss: 504.1694 - val_acc: 0.0192\n",
      "Epoch 222/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 492.5114 - acc: 0.0291 - val_loss: 501.9111 - val_acc: 0.0192\n",
      "Epoch 223/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 490.4620 - acc: 0.0243 - val_loss: 499.8631 - val_acc: 0.0192\n",
      "Epoch 224/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 488.6408 - acc: 0.0194 - val_loss: 497.8282 - val_acc: 0.0192\n",
      "Epoch 225/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 486.8383 - acc: 0.0194 - val_loss: 495.7936 - val_acc: 0.0192\n",
      "Epoch 226/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 485.0625 - acc: 0.0194 - val_loss: 493.7595 - val_acc: 0.0288\n",
      "Epoch 227/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 483.3131 - acc: 0.0243 - val_loss: 491.7133 - val_acc: 0.0288\n",
      "Epoch 228/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 481.5905 - acc: 0.0243 - val_loss: 489.5941 - val_acc: 0.0288\n",
      "Epoch 229/1000\n",
      "412/412 [==============================] - 0s 313us/step - loss: 479.8993 - acc: 0.0218 - val_loss: 487.5146 - val_acc: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 478.2344 - acc: 0.0218 - val_loss: 485.4904 - val_acc: 0.0288\n",
      "Epoch 231/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 476.5909 - acc: 0.0194 - val_loss: 483.5262 - val_acc: 0.0288\n",
      "Epoch 232/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 474.9671 - acc: 0.0194 - val_loss: 481.6198 - val_acc: 0.0288\n",
      "Epoch 233/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 473.3622 - acc: 0.0194 - val_loss: 479.7635 - val_acc: 0.0288\n",
      "Epoch 234/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 471.7753 - acc: 0.0170 - val_loss: 477.9341 - val_acc: 0.0288\n",
      "Epoch 235/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 470.2067 - acc: 0.0170 - val_loss: 476.1006 - val_acc: 0.0288\n",
      "Epoch 236/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 468.6556 - acc: 0.0194 - val_loss: 474.2847 - val_acc: 0.0288\n",
      "Epoch 237/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 467.1267 - acc: 0.0194 - val_loss: 472.4659 - val_acc: 0.0288\n",
      "Epoch 238/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 465.6220 - acc: 0.0170 - val_loss: 470.6998 - val_acc: 0.0288\n",
      "Epoch 239/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 464.1370 - acc: 0.0170 - val_loss: 468.9741 - val_acc: 0.0192\n",
      "Epoch 240/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 462.6706 - acc: 0.0194 - val_loss: 467.2917 - val_acc: 0.0192\n",
      "Epoch 241/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 461.2206 - acc: 0.0170 - val_loss: 465.6551 - val_acc: 0.0192\n",
      "Epoch 242/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 459.7864 - acc: 0.0170 - val_loss: 464.0585 - val_acc: 0.0192\n",
      "Epoch 243/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 458.3687 - acc: 0.0146 - val_loss: 462.4926 - val_acc: 0.0192\n",
      "Epoch 244/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 456.9693 - acc: 0.0146 - val_loss: 460.9392 - val_acc: 0.0192\n",
      "Epoch 245/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 455.5848 - acc: 0.0170 - val_loss: 459.3882 - val_acc: 0.0192\n",
      "Epoch 246/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 454.2111 - acc: 0.0170 - val_loss: 457.8418 - val_acc: 0.0192\n",
      "Epoch 247/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 452.8486 - acc: 0.0170 - val_loss: 456.3113 - val_acc: 0.0192\n",
      "Epoch 248/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 451.4978 - acc: 0.0194 - val_loss: 454.8122 - val_acc: 0.0192\n",
      "Epoch 249/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 450.1619 - acc: 0.0194 - val_loss: 453.3549 - val_acc: 0.0192\n",
      "Epoch 250/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 448.8375 - acc: 0.0194 - val_loss: 451.9324 - val_acc: 0.0288\n",
      "Epoch 251/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 447.5250 - acc: 0.0218 - val_loss: 450.5258 - val_acc: 0.0288\n",
      "Epoch 252/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 446.2234 - acc: 0.0218 - val_loss: 449.1088 - val_acc: 0.0288\n",
      "Epoch 253/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 444.9302 - acc: 0.0218 - val_loss: 447.6777 - val_acc: 0.0288\n",
      "Epoch 254/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 443.6433 - acc: 0.0243 - val_loss: 446.2450 - val_acc: 0.0288\n",
      "Epoch 255/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 442.3640 - acc: 0.0243 - val_loss: 444.8360 - val_acc: 0.0288\n",
      "Epoch 256/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 441.0925 - acc: 0.0243 - val_loss: 443.4658 - val_acc: 0.0288\n",
      "Epoch 257/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 439.8296 - acc: 0.0243 - val_loss: 442.1168 - val_acc: 0.0288\n",
      "Epoch 258/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 438.5732 - acc: 0.0243 - val_loss: 440.7791 - val_acc: 0.0288\n",
      "Epoch 259/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 437.3283 - acc: 0.0267 - val_loss: 439.4337 - val_acc: 0.0288\n",
      "Epoch 260/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 436.0906 - acc: 0.0267 - val_loss: 438.0794 - val_acc: 0.0288\n",
      "Epoch 261/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 434.8660 - acc: 0.0267 - val_loss: 436.7226 - val_acc: 0.0288\n",
      "Epoch 262/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 433.6537 - acc: 0.0267 - val_loss: 435.3738 - val_acc: 0.0288\n",
      "Epoch 263/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 432.4566 - acc: 0.0267 - val_loss: 434.0486 - val_acc: 0.0288\n",
      "Epoch 264/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 431.2678 - acc: 0.0267 - val_loss: 432.7528 - val_acc: 0.0288\n",
      "Epoch 265/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 430.0862 - acc: 0.0267 - val_loss: 431.4778 - val_acc: 0.0288\n",
      "Epoch 266/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 428.9127 - acc: 0.0267 - val_loss: 430.2121 - val_acc: 0.0288\n",
      "Epoch 267/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 427.7465 - acc: 0.0243 - val_loss: 428.9506 - val_acc: 0.0288\n",
      "Epoch 268/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 426.5873 - acc: 0.0218 - val_loss: 427.6978 - val_acc: 0.0288\n",
      "Epoch 269/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 425.4350 - acc: 0.0218 - val_loss: 426.4621 - val_acc: 0.0288\n",
      "Epoch 270/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 424.2899 - acc: 0.0218 - val_loss: 425.2524 - val_acc: 0.0288\n",
      "Epoch 271/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 423.1519 - acc: 0.0218 - val_loss: 424.0669 - val_acc: 0.0288\n",
      "Epoch 272/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 422.0206 - acc: 0.0218 - val_loss: 422.9025 - val_acc: 0.0288\n",
      "Epoch 273/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 420.8961 - acc: 0.0218 - val_loss: 421.7390 - val_acc: 0.0288\n",
      "Epoch 274/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 419.7780 - acc: 0.0218 - val_loss: 420.5709 - val_acc: 0.0288\n",
      "Epoch 275/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 418.6697 - acc: 0.0218 - val_loss: 419.4070 - val_acc: 0.0288\n",
      "Epoch 276/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 417.5712 - acc: 0.0218 - val_loss: 418.2538 - val_acc: 0.0096\n",
      "Epoch 277/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 416.4806 - acc: 0.0218 - val_loss: 417.1199 - val_acc: 0.0096\n",
      "Epoch 278/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 415.3958 - acc: 0.0218 - val_loss: 416.0031 - val_acc: 0.0096\n",
      "Epoch 279/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 414.3161 - acc: 0.0243 - val_loss: 414.8952 - val_acc: 0.0096\n",
      "Epoch 280/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 413.2414 - acc: 0.0243 - val_loss: 413.7873 - val_acc: 0.0096\n",
      "Epoch 281/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 412.1721 - acc: 0.0267 - val_loss: 412.6759 - val_acc: 0.0096\n",
      "Epoch 282/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 411.1086 - acc: 0.0243 - val_loss: 411.5677 - val_acc: 0.0096\n",
      "Epoch 283/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 410.0522 - acc: 0.0243 - val_loss: 410.4704 - val_acc: 0.0096\n",
      "Epoch 284/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 408.9997 - acc: 0.0218 - val_loss: 409.3770 - val_acc: 0.0096\n",
      "Epoch 285/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 407.9533 - acc: 0.0218 - val_loss: 408.2878 - val_acc: 0.0096\n",
      "Epoch 286/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 406.9088 - acc: 0.0218 - val_loss: 407.2022 - val_acc: 0.0096\n",
      "Epoch 287/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 405.8662 - acc: 0.0218 - val_loss: 406.1190 - val_acc: 0.0096\n",
      "Epoch 288/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 404.8283 - acc: 0.0218 - val_loss: 405.0340 - val_acc: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 403.7999 - acc: 0.0194 - val_loss: 403.9539 - val_acc: 0.0096\n",
      "Epoch 290/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 402.7778 - acc: 0.0194 - val_loss: 402.8826 - val_acc: 0.0096\n",
      "Epoch 291/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 401.7613 - acc: 0.0194 - val_loss: 401.8260 - val_acc: 0.0096\n",
      "Epoch 292/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 400.7486 - acc: 0.0194 - val_loss: 400.7855 - val_acc: 0.0096\n",
      "Epoch 293/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 399.7402 - acc: 0.0194 - val_loss: 399.7621 - val_acc: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 398.7374 - acc: 0.0194 - val_loss: 398.7510 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 397.7415 - acc: 0.0194 - val_loss: 397.7487 - val_acc: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 396.7542 - acc: 0.0194 - val_loss: 396.7543 - val_acc: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 395.7726 - acc: 0.0194 - val_loss: 395.7709 - val_acc: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 394.7948 - acc: 0.0194 - val_loss: 394.8016 - val_acc: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 393.8210 - acc: 0.0194 - val_loss: 393.8429 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 392.8563 - acc: 0.0194 - val_loss: 392.9047 - val_acc: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 391.8981 - acc: 0.0194 - val_loss: 391.9793 - val_acc: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 390.9439 - acc: 0.0194 - val_loss: 391.0658 - val_acc: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 389.9938 - acc: 0.0194 - val_loss: 390.1626 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 389.0469 - acc: 0.0170 - val_loss: 389.2791 - val_acc: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 388.1046 - acc: 0.0146 - val_loss: 388.4070 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 387.1710 - acc: 0.0170 - val_loss: 387.5367 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 386.2408 - acc: 0.0170 - val_loss: 386.6708 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 385.3142 - acc: 0.0170 - val_loss: 385.8007 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 384.3913 - acc: 0.0194 - val_loss: 384.9330 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 383.4769 - acc: 0.0194 - val_loss: 384.0817 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 382.5654 - acc: 0.0218 - val_loss: 383.2310 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 381.6570 - acc: 0.0218 - val_loss: 382.3568 - val_acc: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 380.7543 - acc: 0.0218 - val_loss: 381.4720 - val_acc: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 379.8597 - acc: 0.0218 - val_loss: 380.5706 - val_acc: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 378.9677 - acc: 0.0194 - val_loss: 379.6688 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 378.0788 - acc: 0.0170 - val_loss: 378.7714 - val_acc: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "412/412 [==============================] - 0s 39us/step - loss: 377.1971 - acc: 0.0194 - val_loss: 377.8920 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 376.3198 - acc: 0.0194 - val_loss: 377.0213 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 375.4420 - acc: 0.0194 - val_loss: 376.1445 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 374.5725 - acc: 0.0194 - val_loss: 375.2520 - val_acc: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 373.7072 - acc: 0.0194 - val_loss: 374.3720 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 372.8445 - acc: 0.0194 - val_loss: 373.5032 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 371.9834 - acc: 0.0194 - val_loss: 372.6284 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 371.1270 - acc: 0.0194 - val_loss: 371.7540 - val_acc: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 370.2817 - acc: 0.0194 - val_loss: 370.8910 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 369.4329 - acc: 0.0194 - val_loss: 370.0509 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 368.5879 - acc: 0.0194 - val_loss: 369.1951 - val_acc: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 367.7502 - acc: 0.0194 - val_loss: 368.3390 - val_acc: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 366.9135 - acc: 0.0194 - val_loss: 367.4930 - val_acc: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 366.0775 - acc: 0.0218 - val_loss: 366.6338 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 365.2461 - acc: 0.0218 - val_loss: 365.7890 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 364.4202 - acc: 0.0218 - val_loss: 364.9611 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 363.5942 - acc: 0.0218 - val_loss: 364.1059 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 362.7739 - acc: 0.0218 - val_loss: 363.2513 - val_acc: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 361.9548 - acc: 0.0218 - val_loss: 362.4183 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 361.1404 - acc: 0.0218 - val_loss: 361.5926 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 360.3286 - acc: 0.0243 - val_loss: 360.7525 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 359.5186 - acc: 0.0218 - val_loss: 359.9012 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 358.7120 - acc: 0.0218 - val_loss: 359.0591 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 357.9086 - acc: 0.0218 - val_loss: 358.2485 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 357.1084 - acc: 0.0218 - val_loss: 357.4216 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 356.3086 - acc: 0.0218 - val_loss: 356.5768 - val_acc: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 355.5122 - acc: 0.0218 - val_loss: 355.7256 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 354.7183 - acc: 0.0218 - val_loss: 354.8871 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 353.9263 - acc: 0.0243 - val_loss: 354.0678 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 353.1387 - acc: 0.0243 - val_loss: 353.2571 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 352.3521 - acc: 0.0243 - val_loss: 352.4370 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 351.5672 - acc: 0.0243 - val_loss: 351.6045 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 350.7857 - acc: 0.0243 - val_loss: 350.7950 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 350.0062 - acc: 0.0243 - val_loss: 350.0007 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 349.2285 - acc: 0.0243 - val_loss: 349.1807 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 348.4520 - acc: 0.0243 - val_loss: 348.3380 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 347.6779 - acc: 0.0243 - val_loss: 347.5348 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 346.9052 - acc: 0.0267 - val_loss: 346.7331 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 346.1350 - acc: 0.0267 - val_loss: 345.9165 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 345.3667 - acc: 0.0267 - val_loss: 345.0924 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 344.6011 - acc: 0.0267 - val_loss: 344.3087 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 343.8362 - acc: 0.0243 - val_loss: 343.5102 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 343.0736 - acc: 0.0243 - val_loss: 342.7039 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 342.3130 - acc: 0.0267 - val_loss: 341.9081 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 341.5539 - acc: 0.0243 - val_loss: 341.1206 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 340.7964 - acc: 0.0243 - val_loss: 340.3221 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "412/412 [==============================] - 0s 32us/step - loss: 340.0408 - acc: 0.0243 - val_loss: 339.5239 - val_acc: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 339.2867 - acc: 0.0243 - val_loss: 338.7277 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 338.5337 - acc: 0.0243 - val_loss: 337.9329 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 337.7846 - acc: 0.0243 - val_loss: 337.1729 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 337.0344 - acc: 0.0243 - val_loss: 336.4127 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 336.2868 - acc: 0.0243 - val_loss: 335.6279 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 335.5411 - acc: 0.0218 - val_loss: 334.8822 - val_acc: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 334.7961 - acc: 0.0218 - val_loss: 334.1487 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 334.0542 - acc: 0.0218 - val_loss: 333.3842 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 333.3143 - acc: 0.0218 - val_loss: 332.5906 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 332.5757 - acc: 0.0243 - val_loss: 331.8643 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 331.8378 - acc: 0.0218 - val_loss: 331.1271 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 331.1025 - acc: 0.0218 - val_loss: 330.3471 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 330.3675 - acc: 0.0218 - val_loss: 329.5997 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 329.6352 - acc: 0.0218 - val_loss: 328.8670 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 328.9043 - acc: 0.0243 - val_loss: 328.1360 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 328.1770 - acc: 0.0243 - val_loss: 327.3784 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 327.4501 - acc: 0.0291 - val_loss: 326.6415 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 326.7246 - acc: 0.0316 - val_loss: 325.9420 - val_acc: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 326.0002 - acc: 0.0291 - val_loss: 325.2152 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 325.2768 - acc: 0.0267 - val_loss: 324.4728 - val_acc: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 324.5547 - acc: 0.0291 - val_loss: 323.7666 - val_acc: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 323.8335 - acc: 0.0291 - val_loss: 323.0666 - val_acc: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 323.1136 - acc: 0.0267 - val_loss: 322.3329 - val_acc: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 322.3944 - acc: 0.0291 - val_loss: 321.6131 - val_acc: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 321.6764 - acc: 0.0291 - val_loss: 320.9321 - val_acc: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 320.9591 - acc: 0.0267 - val_loss: 320.2174 - val_acc: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 320.2425 - acc: 0.0267 - val_loss: 319.4935 - val_acc: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 319.5270 - acc: 0.0291 - val_loss: 318.8137 - val_acc: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 318.8149 - acc: 0.0267 - val_loss: 318.0549 - val_acc: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 318.0994 - acc: 0.0291 - val_loss: 317.3459 - val_acc: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 317.3873 - acc: 0.0267 - val_loss: 316.6315 - val_acc: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 316.6762 - acc: 0.0267 - val_loss: 315.8883 - val_acc: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 315.9655 - acc: 0.0267 - val_loss: 315.1990 - val_acc: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 315.2549 - acc: 0.0243 - val_loss: 314.5114 - val_acc: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 314.5448 - acc: 0.0267 - val_loss: 313.7984 - val_acc: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 313.8348 - acc: 0.0267 - val_loss: 313.1263 - val_acc: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 313.1288 - acc: 0.0243 - val_loss: 312.4069 - val_acc: 0.0096\n",
      "Epoch 401/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 312.4214 - acc: 0.0267 - val_loss: 311.6816 - val_acc: 0.0096\n",
      "Epoch 402/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 311.7125 - acc: 0.0267 - val_loss: 310.9995 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 311.0075 - acc: 0.0243 - val_loss: 310.2649 - val_acc: 0.0096\n",
      "Epoch 404/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 310.3015 - acc: 0.0267 - val_loss: 309.5786 - val_acc: 0.0096\n",
      "Epoch 405/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 309.5963 - acc: 0.0267 - val_loss: 308.8669 - val_acc: 0.0096\n",
      "Epoch 406/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 308.8913 - acc: 0.0267 - val_loss: 308.1944 - val_acc: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 308.1890 - acc: 0.0243 - val_loss: 307.4263 - val_acc: 0.0192\n",
      "Epoch 408/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 307.4857 - acc: 0.0267 - val_loss: 306.7844 - val_acc: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 306.7829 - acc: 0.0243 - val_loss: 306.0215 - val_acc: 0.0192\n",
      "Epoch 410/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 306.0813 - acc: 0.0267 - val_loss: 305.3437 - val_acc: 0.0192\n",
      "Epoch 411/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 305.3786 - acc: 0.0243 - val_loss: 304.6739 - val_acc: 0.0192\n",
      "Epoch 412/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 304.6803 - acc: 0.0243 - val_loss: 303.9221 - val_acc: 0.0192\n",
      "Epoch 413/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 303.9811 - acc: 0.0243 - val_loss: 303.2555 - val_acc: 0.0192\n",
      "Epoch 414/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 303.2796 - acc: 0.0218 - val_loss: 302.5118 - val_acc: 0.0192\n",
      "Epoch 415/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 302.5787 - acc: 0.0218 - val_loss: 301.8077 - val_acc: 0.0192\n",
      "Epoch 416/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 301.8796 - acc: 0.0218 - val_loss: 301.1488 - val_acc: 0.0192\n",
      "Epoch 417/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 301.1842 - acc: 0.0218 - val_loss: 300.4051 - val_acc: 0.0192\n",
      "Epoch 418/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 300.4888 - acc: 0.0243 - val_loss: 299.7263 - val_acc: 0.0192\n",
      "Epoch 419/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 299.7889 - acc: 0.0218 - val_loss: 298.9943 - val_acc: 0.0192\n",
      "Epoch 420/1000\n",
      "412/412 [==============================] - 0s 34us/step - loss: 299.0910 - acc: 0.0218 - val_loss: 298.2003 - val_acc: 0.0192\n",
      "Epoch 421/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 298.4037 - acc: 0.0243 - val_loss: 297.6162 - val_acc: 0.0096\n",
      "Epoch 422/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 297.7098 - acc: 0.0218 - val_loss: 296.8629 - val_acc: 0.0192\n",
      "Epoch 423/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 297.0071 - acc: 0.0243 - val_loss: 296.1811 - val_acc: 0.0192\n",
      "Epoch 424/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 296.3154 - acc: 0.0243 - val_loss: 295.6168 - val_acc: 0.0096\n",
      "Epoch 425/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 295.6297 - acc: 0.0243 - val_loss: 294.7536 - val_acc: 0.0192\n",
      "Epoch 426/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 294.9368 - acc: 0.0243 - val_loss: 294.1467 - val_acc: 0.0192\n",
      "Epoch 427/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 294.2395 - acc: 0.0243 - val_loss: 293.3848 - val_acc: 0.0192\n",
      "Epoch 428/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 293.5492 - acc: 0.0243 - val_loss: 292.6808 - val_acc: 0.0192\n",
      "Epoch 429/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 292.8589 - acc: 0.0218 - val_loss: 292.0341 - val_acc: 0.0192\n",
      "Epoch 430/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 292.1701 - acc: 0.0243 - val_loss: 291.3541 - val_acc: 0.0192\n",
      "Epoch 431/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 291.4817 - acc: 0.0218 - val_loss: 290.6938 - val_acc: 0.0192\n",
      "Epoch 432/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 290.7937 - acc: 0.0218 - val_loss: 289.9997 - val_acc: 0.0192\n",
      "Epoch 433/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 290.1049 - acc: 0.0218 - val_loss: 289.3375 - val_acc: 0.0192\n",
      "Epoch 434/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 289.4172 - acc: 0.0243 - val_loss: 288.6580 - val_acc: 0.0192\n",
      "Epoch 435/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 288.7307 - acc: 0.0218 - val_loss: 287.9839 - val_acc: 0.0192\n",
      "Epoch 436/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 288.0445 - acc: 0.0218 - val_loss: 287.3830 - val_acc: 0.0192\n",
      "Epoch 437/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 287.3588 - acc: 0.0267 - val_loss: 286.6886 - val_acc: 0.0192\n",
      "Epoch 438/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 286.6732 - acc: 0.0218 - val_loss: 286.1592 - val_acc: 0.0192\n",
      "Epoch 439/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 285.9905 - acc: 0.0267 - val_loss: 285.4173 - val_acc: 0.0192\n",
      "Epoch 440/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 285.3085 - acc: 0.0243 - val_loss: 284.8933 - val_acc: 0.0192\n",
      "Epoch 441/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 284.6269 - acc: 0.0267 - val_loss: 284.0962 - val_acc: 0.0192\n",
      "Epoch 442/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 283.9449 - acc: 0.0243 - val_loss: 283.5442 - val_acc: 0.0192\n",
      "Epoch 443/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 283.2636 - acc: 0.0267 - val_loss: 282.7596 - val_acc: 0.0192\n",
      "Epoch 444/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 282.5833 - acc: 0.0243 - val_loss: 282.1548 - val_acc: 0.0192\n",
      "Epoch 445/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 281.9043 - acc: 0.0267 - val_loss: 281.4278 - val_acc: 0.0192\n",
      "Epoch 446/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 281.2270 - acc: 0.0243 - val_loss: 280.7639 - val_acc: 0.0192\n",
      "Epoch 447/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 280.5513 - acc: 0.0218 - val_loss: 280.0907 - val_acc: 0.0192\n",
      "Epoch 448/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 279.8775 - acc: 0.0243 - val_loss: 279.4445 - val_acc: 0.0192\n",
      "Epoch 449/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 279.2029 - acc: 0.0218 - val_loss: 278.7811 - val_acc: 0.0192\n",
      "Epoch 450/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 278.5299 - acc: 0.0243 - val_loss: 278.2108 - val_acc: 0.0192\n",
      "Epoch 451/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 277.8578 - acc: 0.0218 - val_loss: 277.5002 - val_acc: 0.0192\n",
      "Epoch 452/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 277.1867 - acc: 0.0243 - val_loss: 276.9958 - val_acc: 0.0192\n",
      "Epoch 453/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 276.5175 - acc: 0.0243 - val_loss: 276.2113 - val_acc: 0.0192\n",
      "Epoch 454/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 275.8507 - acc: 0.0243 - val_loss: 275.8508 - val_acc: 0.0192\n",
      "Epoch 455/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 275.1897 - acc: 0.0218 - val_loss: 274.9094 - val_acc: 0.0192\n",
      "Epoch 456/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 274.5341 - acc: 0.0267 - val_loss: 274.7587 - val_acc: 0.0096\n",
      "Epoch 457/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 273.8841 - acc: 0.0218 - val_loss: 273.6582 - val_acc: 0.0192\n",
      "Epoch 458/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 273.2177 - acc: 0.0267 - val_loss: 273.4219 - val_acc: 0.0192\n",
      "Epoch 459/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 272.5355 - acc: 0.0243 - val_loss: 272.5957 - val_acc: 0.0192\n",
      "Epoch 460/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 271.8575 - acc: 0.0291 - val_loss: 271.9167 - val_acc: 0.0192\n",
      "Epoch 461/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 271.2042 - acc: 0.0291 - val_loss: 271.6010 - val_acc: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 270.5625 - acc: 0.0243 - val_loss: 270.6159 - val_acc: 0.0192\n",
      "Epoch 463/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 269.9060 - acc: 0.0291 - val_loss: 270.3002 - val_acc: 0.0192\n",
      "Epoch 464/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 269.2342 - acc: 0.0218 - val_loss: 269.5753 - val_acc: 0.0192\n",
      "Epoch 465/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 268.5621 - acc: 0.0267 - val_loss: 268.9130 - val_acc: 0.0192\n",
      "Epoch 466/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 267.8954 - acc: 0.0267 - val_loss: 268.6802 - val_acc: 0.0192\n",
      "Epoch 467/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 267.2220 - acc: 0.0194 - val_loss: 267.8187 - val_acc: 0.0192\n",
      "Epoch 468/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 266.5274 - acc: 0.0243 - val_loss: 267.6240 - val_acc: 0.0192\n",
      "Epoch 469/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 265.8282 - acc: 0.0194 - val_loss: 267.0269 - val_acc: 0.0192\n",
      "Epoch 470/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 265.2055 - acc: 0.0243 - val_loss: 266.3862 - val_acc: 0.0192\n",
      "Epoch 471/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 264.6370 - acc: 0.0218 - val_loss: 265.9437 - val_acc: 0.0192\n",
      "Epoch 472/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 263.9614 - acc: 0.0243 - val_loss: 264.9635 - val_acc: 0.0192\n",
      "Epoch 473/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 263.2244 - acc: 0.0218 - val_loss: 264.4539 - val_acc: 0.0192\n",
      "Epoch 474/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 262.5517 - acc: 0.0218 - val_loss: 263.5745 - val_acc: 0.0192\n",
      "Epoch 475/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 261.9148 - acc: 0.0194 - val_loss: 262.8578 - val_acc: 0.0192\n",
      "Epoch 476/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 261.2801 - acc: 0.0194 - val_loss: 262.4116 - val_acc: 0.0192\n",
      "Epoch 477/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 260.6284 - acc: 0.0170 - val_loss: 261.5255 - val_acc: 0.0192\n",
      "Epoch 478/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 259.9619 - acc: 0.0194 - val_loss: 261.2571 - val_acc: 0.0192\n",
      "Epoch 479/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 259.2795 - acc: 0.0170 - val_loss: 260.2650 - val_acc: 0.0192\n",
      "Epoch 480/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 258.6528 - acc: 0.0243 - val_loss: 260.0544 - val_acc: 0.0192\n",
      "Epoch 481/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 258.0089 - acc: 0.0170 - val_loss: 258.9889 - val_acc: 0.0192\n",
      "Epoch 482/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 257.3484 - acc: 0.0218 - val_loss: 258.5792 - val_acc: 0.0192\n",
      "Epoch 483/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 256.6829 - acc: 0.0194 - val_loss: 257.7541 - val_acc: 0.0192\n",
      "Epoch 484/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 256.0316 - acc: 0.0218 - val_loss: 257.2407 - val_acc: 0.0192\n",
      "Epoch 485/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 255.3836 - acc: 0.0194 - val_loss: 256.3802 - val_acc: 0.0192\n",
      "Epoch 486/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 254.7704 - acc: 0.0218 - val_loss: 256.3313 - val_acc: 0.0096\n",
      "Epoch 487/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 254.1693 - acc: 0.0170 - val_loss: 255.0219 - val_acc: 0.0288\n",
      "Epoch 488/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 253.5957 - acc: 0.0243 - val_loss: 255.5457 - val_acc: 0.0096\n",
      "Epoch 489/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 253.0542 - acc: 0.0194 - val_loss: 253.8100 - val_acc: 0.0385\n",
      "Epoch 490/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 252.4023 - acc: 0.0218 - val_loss: 253.8150 - val_acc: 0.0192\n",
      "Epoch 491/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 251.6031 - acc: 0.0243 - val_loss: 253.0948 - val_acc: 0.0192\n",
      "Epoch 492/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 250.9545 - acc: 0.0243 - val_loss: 251.9224 - val_acc: 0.0385\n",
      "Epoch 493/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 250.4877 - acc: 0.0291 - val_loss: 252.3998 - val_acc: 0.0096\n",
      "Epoch 494/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 249.8778 - acc: 0.0291 - val_loss: 250.8573 - val_acc: 0.0288\n",
      "Epoch 495/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 249.1020 - acc: 0.0316 - val_loss: 250.4426 - val_acc: 0.0192\n",
      "Epoch 496/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 248.4499 - acc: 0.0267 - val_loss: 250.3511 - val_acc: 0.0096\n",
      "Epoch 497/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 247.9378 - acc: 0.0243 - val_loss: 249.0488 - val_acc: 0.0385\n",
      "Epoch 498/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 247.3389 - acc: 0.0267 - val_loss: 248.8270 - val_acc: 0.0192\n",
      "Epoch 499/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 246.6089 - acc: 0.0267 - val_loss: 248.1705 - val_acc: 0.0192\n",
      "Epoch 500/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 245.9957 - acc: 0.0267 - val_loss: 247.1273 - val_acc: 0.0288\n",
      "Epoch 501/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 245.4981 - acc: 0.0316 - val_loss: 247.1669 - val_acc: 0.0096\n",
      "Epoch 502/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 244.8909 - acc: 0.0243 - val_loss: 246.1688 - val_acc: 0.0192\n",
      "Epoch 503/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 244.1874 - acc: 0.0316 - val_loss: 245.6019 - val_acc: 0.0192\n",
      "Epoch 504/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 243.5476 - acc: 0.0243 - val_loss: 245.5805 - val_acc: 0.0192\n",
      "Epoch 505/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 243.0117 - acc: 0.0267 - val_loss: 244.8385 - val_acc: 0.0288\n",
      "Epoch 506/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 242.4183 - acc: 0.0267 - val_loss: 244.6353 - val_acc: 0.0192\n",
      "Epoch 507/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 241.8094 - acc: 0.0267 - val_loss: 244.1868 - val_acc: 0.0192\n",
      "Epoch 508/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 241.2111 - acc: 0.0291 - val_loss: 243.3257 - val_acc: 0.0288\n",
      "Epoch 509/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 240.6127 - acc: 0.0267 - val_loss: 243.0270 - val_acc: 0.0192\n",
      "Epoch 510/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 239.9948 - acc: 0.0267 - val_loss: 242.0628 - val_acc: 0.0192\n",
      "Epoch 511/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 239.3667 - acc: 0.0267 - val_loss: 241.3586 - val_acc: 0.0192\n",
      "Epoch 512/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 238.7511 - acc: 0.0243 - val_loss: 240.7958 - val_acc: 0.0192\n",
      "Epoch 513/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 238.1447 - acc: 0.0194 - val_loss: 239.7275 - val_acc: 0.0288\n",
      "Epoch 514/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 237.5459 - acc: 0.0218 - val_loss: 239.6034 - val_acc: 0.0192\n",
      "Epoch 515/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 236.9724 - acc: 0.0170 - val_loss: 238.5429 - val_acc: 0.0288\n",
      "Epoch 516/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 236.4092 - acc: 0.0243 - val_loss: 238.3937 - val_acc: 0.0192\n",
      "Epoch 517/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 235.7639 - acc: 0.0170 - val_loss: 237.4951 - val_acc: 0.0288\n",
      "Epoch 518/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 235.1526 - acc: 0.0218 - val_loss: 237.1924 - val_acc: 0.0192\n",
      "Epoch 519/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 234.5655 - acc: 0.0194 - val_loss: 236.9611 - val_acc: 0.0192\n",
      "Epoch 520/1000\n",
      "412/412 [==============================] - 0s 34us/step - loss: 233.9924 - acc: 0.0194 - val_loss: 236.0540 - val_acc: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 233.4208 - acc: 0.0218 - val_loss: 236.1582 - val_acc: 0.0192\n",
      "Epoch 522/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 232.8367 - acc: 0.0170 - val_loss: 235.1199 - val_acc: 0.0288\n",
      "Epoch 523/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 232.2373 - acc: 0.0218 - val_loss: 235.0335 - val_acc: 0.0192\n",
      "Epoch 524/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 231.6330 - acc: 0.0194 - val_loss: 234.3056 - val_acc: 0.0192\n",
      "Epoch 525/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 231.0343 - acc: 0.0243 - val_loss: 233.8082 - val_acc: 0.0288\n",
      "Epoch 526/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 230.4468 - acc: 0.0243 - val_loss: 233.4870 - val_acc: 0.0192\n",
      "Epoch 527/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 229.8678 - acc: 0.0170 - val_loss: 232.6256 - val_acc: 0.0385\n",
      "Epoch 528/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 229.2938 - acc: 0.0218 - val_loss: 232.5962 - val_acc: 0.0288\n",
      "Epoch 529/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 228.7222 - acc: 0.0170 - val_loss: 231.4806 - val_acc: 0.0385\n",
      "Epoch 530/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 228.1519 - acc: 0.0218 - val_loss: 231.6623 - val_acc: 0.0288\n",
      "Epoch 531/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 227.5837 - acc: 0.0146 - val_loss: 230.3547 - val_acc: 0.0385\n",
      "Epoch 532/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 227.0185 - acc: 0.0218 - val_loss: 230.7388 - val_acc: 0.0288\n",
      "Epoch 533/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 226.4551 - acc: 0.0170 - val_loss: 229.2649 - val_acc: 0.0385\n",
      "Epoch 534/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 225.8903 - acc: 0.0194 - val_loss: 229.7821 - val_acc: 0.0192\n",
      "Epoch 535/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 225.3178 - acc: 0.0267 - val_loss: 228.2561 - val_acc: 0.0385\n",
      "Epoch 536/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 224.7358 - acc: 0.0194 - val_loss: 228.7139 - val_acc: 0.0288\n",
      "Epoch 537/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 224.1422 - acc: 0.0218 - val_loss: 227.3617 - val_acc: 0.0385\n",
      "Epoch 538/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 223.5415 - acc: 0.0218 - val_loss: 227.5479 - val_acc: 0.0288\n",
      "Epoch 539/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 222.9395 - acc: 0.0194 - val_loss: 226.6333 - val_acc: 0.0481\n",
      "Epoch 540/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 222.3394 - acc: 0.0243 - val_loss: 226.4237 - val_acc: 0.0385\n",
      "Epoch 541/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 221.7473 - acc: 0.0243 - val_loss: 226.0945 - val_acc: 0.0288\n",
      "Epoch 542/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 221.1728 - acc: 0.0243 - val_loss: 225.3440 - val_acc: 0.0577\n",
      "Epoch 543/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 220.6294 - acc: 0.0243 - val_loss: 225.6481 - val_acc: 0.0288\n",
      "Epoch 544/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 220.1287 - acc: 0.0243 - val_loss: 224.1241 - val_acc: 0.0385\n",
      "Epoch 545/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 219.6712 - acc: 0.0267 - val_loss: 225.1799 - val_acc: 0.0192\n",
      "Epoch 546/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 219.2404 - acc: 0.0218 - val_loss: 222.7648 - val_acc: 0.0288\n",
      "Epoch 547/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 218.8285 - acc: 0.0267 - val_loss: 224.3213 - val_acc: 0.0192\n",
      "Epoch 548/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 218.3006 - acc: 0.0291 - val_loss: 221.6191 - val_acc: 0.0385\n",
      "Epoch 549/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 217.5521 - acc: 0.0243 - val_loss: 221.8723 - val_acc: 0.0385\n",
      "Epoch 550/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 216.7096 - acc: 0.0194 - val_loss: 221.4835 - val_acc: 0.0385\n",
      "Epoch 551/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 216.1781 - acc: 0.0170 - val_loss: 220.1348 - val_acc: 0.0385\n",
      "Epoch 552/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 215.8419 - acc: 0.0243 - val_loss: 221.4455 - val_acc: 0.0192\n",
      "Epoch 553/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 215.3617 - acc: 0.0267 - val_loss: 219.4490 - val_acc: 0.0481\n",
      "Epoch 554/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 214.6284 - acc: 0.0194 - val_loss: 219.4724 - val_acc: 0.0577\n",
      "Epoch 555/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 213.9274 - acc: 0.0194 - val_loss: 219.4672 - val_acc: 0.0385\n",
      "Epoch 556/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 213.4789 - acc: 0.0170 - val_loss: 217.9777 - val_acc: 0.0481\n",
      "Epoch 557/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 213.0767 - acc: 0.0170 - val_loss: 218.6574 - val_acc: 0.0192\n",
      "Epoch 558/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 212.4757 - acc: 0.0218 - val_loss: 217.1053 - val_acc: 0.0673\n",
      "Epoch 559/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 211.7813 - acc: 0.0194 - val_loss: 216.5595 - val_acc: 0.0673\n",
      "Epoch 560/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 211.2308 - acc: 0.0194 - val_loss: 216.8120 - val_acc: 0.0192\n",
      "Epoch 561/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 210.7997 - acc: 0.0218 - val_loss: 215.1642 - val_acc: 0.0577\n",
      "Epoch 562/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 210.2959 - acc: 0.0194 - val_loss: 215.4601 - val_acc: 0.0288\n",
      "Epoch 563/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 209.6634 - acc: 0.0170 - val_loss: 214.4390 - val_acc: 0.0577\n",
      "Epoch 564/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 209.0607 - acc: 0.0243 - val_loss: 213.6234 - val_acc: 0.0577\n",
      "Epoch 565/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 208.5785 - acc: 0.0194 - val_loss: 214.0968 - val_acc: 0.0096\n",
      "Epoch 566/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 208.1198 - acc: 0.0218 - val_loss: 212.5095 - val_acc: 0.0577\n",
      "Epoch 567/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 207.5703 - acc: 0.0194 - val_loss: 212.8387 - val_acc: 0.0192\n",
      "Epoch 568/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 206.9560 - acc: 0.0194 - val_loss: 211.9137 - val_acc: 0.0577\n",
      "Epoch 569/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 206.3639 - acc: 0.0243 - val_loss: 211.2870 - val_acc: 0.0673\n",
      "Epoch 570/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 205.8427 - acc: 0.0194 - val_loss: 211.4810 - val_acc: 0.0192\n",
      "Epoch 571/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 205.3530 - acc: 0.0194 - val_loss: 210.1637 - val_acc: 0.0577\n",
      "Epoch 572/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 204.8209 - acc: 0.0194 - val_loss: 210.4155 - val_acc: 0.0192\n",
      "Epoch 573/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 204.2428 - acc: 0.0218 - val_loss: 209.4094 - val_acc: 0.0577\n",
      "Epoch 574/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 203.6575 - acc: 0.0218 - val_loss: 209.0175 - val_acc: 0.0481\n",
      "Epoch 575/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 203.1032 - acc: 0.0243 - val_loss: 208.8659 - val_acc: 0.0385\n",
      "Epoch 576/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 202.5794 - acc: 0.0218 - val_loss: 207.8575 - val_acc: 0.0577\n",
      "Epoch 577/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 202.0633 - acc: 0.0194 - val_loss: 208.1667 - val_acc: 0.0288\n",
      "Epoch 578/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 201.5348 - acc: 0.0194 - val_loss: 206.9389 - val_acc: 0.0481\n",
      "Epoch 579/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 200.9867 - acc: 0.0194 - val_loss: 207.1593 - val_acc: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 200.4212 - acc: 0.0218 - val_loss: 206.2229 - val_acc: 0.0577\n",
      "Epoch 581/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 199.8454 - acc: 0.0243 - val_loss: 206.0549 - val_acc: 0.0481\n",
      "Epoch 582/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 199.2805 - acc: 0.0243 - val_loss: 205.7021 - val_acc: 0.0481\n",
      "Epoch 583/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 198.7206 - acc: 0.0243 - val_loss: 205.1208 - val_acc: 0.0385\n",
      "Epoch 584/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 198.1766 - acc: 0.0243 - val_loss: 205.2783 - val_acc: 0.0385\n",
      "Epoch 585/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 197.6492 - acc: 0.0218 - val_loss: 204.2974 - val_acc: 0.0385\n",
      "Epoch 586/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 197.1409 - acc: 0.0218 - val_loss: 204.8624 - val_acc: 0.0192\n",
      "Epoch 587/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 196.6875 - acc: 0.0267 - val_loss: 203.3548 - val_acc: 0.0481\n",
      "Epoch 588/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 196.2702 - acc: 0.0243 - val_loss: 204.5771 - val_acc: 0.0096\n",
      "Epoch 589/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 195.9127 - acc: 0.0316 - val_loss: 202.2882 - val_acc: 0.0288\n",
      "Epoch 590/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 195.5981 - acc: 0.0267 - val_loss: 204.1956 - val_acc: 0.0096\n",
      "Epoch 591/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 195.2018 - acc: 0.0413 - val_loss: 201.1269 - val_acc: 0.0288\n",
      "Epoch 592/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 194.5308 - acc: 0.0267 - val_loss: 201.9175 - val_acc: 0.0096\n",
      "Epoch 593/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 193.5860 - acc: 0.0340 - val_loss: 200.2506 - val_acc: 0.0481\n",
      "Epoch 594/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 192.7925 - acc: 0.0267 - val_loss: 199.3121 - val_acc: 0.0385\n",
      "Epoch 595/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 192.3984 - acc: 0.0218 - val_loss: 200.3193 - val_acc: 0.0192\n",
      "Epoch 596/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 192.1908 - acc: 0.0364 - val_loss: 198.0325 - val_acc: 0.0385\n",
      "Epoch 597/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 191.7609 - acc: 0.0218 - val_loss: 198.8710 - val_acc: 0.0096\n",
      "Epoch 598/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 190.9936 - acc: 0.0340 - val_loss: 197.2350 - val_acc: 0.0385\n",
      "Epoch 599/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 190.2150 - acc: 0.0267 - val_loss: 196.7248 - val_acc: 0.0385\n",
      "Epoch 600/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 189.7195 - acc: 0.0243 - val_loss: 197.3736 - val_acc: 0.0192\n",
      "Epoch 601/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 189.4362 - acc: 0.0316 - val_loss: 195.6507 - val_acc: 0.0481\n",
      "Epoch 602/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 189.0437 - acc: 0.0218 - val_loss: 196.2952 - val_acc: 0.0192\n",
      "Epoch 603/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 188.3873 - acc: 0.0316 - val_loss: 194.7661 - val_acc: 0.0385\n",
      "Epoch 604/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 187.6790 - acc: 0.0267 - val_loss: 194.2242 - val_acc: 0.0385\n",
      "Epoch 605/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 187.1698 - acc: 0.0243 - val_loss: 194.5166 - val_acc: 0.0192\n",
      "Epoch 606/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 186.8136 - acc: 0.0316 - val_loss: 192.9194 - val_acc: 0.0481\n",
      "Epoch 607/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 186.4102 - acc: 0.0243 - val_loss: 193.5054 - val_acc: 0.0096\n",
      "Epoch 608/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 185.8452 - acc: 0.0364 - val_loss: 192.0151 - val_acc: 0.0385\n",
      "Epoch 609/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 185.2067 - acc: 0.0291 - val_loss: 191.7127 - val_acc: 0.0481\n",
      "Epoch 610/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 184.6560 - acc: 0.0267 - val_loss: 191.6874 - val_acc: 0.0385\n",
      "Epoch 611/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 184.2340 - acc: 0.0267 - val_loss: 190.4842 - val_acc: 0.0481\n",
      "Epoch 612/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 183.8381 - acc: 0.0243 - val_loss: 191.0867 - val_acc: 0.0192\n",
      "Epoch 613/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 183.3665 - acc: 0.0316 - val_loss: 189.6237 - val_acc: 0.0481\n",
      "Epoch 614/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 182.8092 - acc: 0.0218 - val_loss: 189.7496 - val_acc: 0.0385\n",
      "Epoch 615/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 182.2320 - acc: 0.0291 - val_loss: 189.0025 - val_acc: 0.0481\n",
      "Epoch 616/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 181.7016 - acc: 0.0267 - val_loss: 188.4048 - val_acc: 0.0385\n",
      "Epoch 617/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 181.2343 - acc: 0.0267 - val_loss: 188.5100 - val_acc: 0.0385\n",
      "Epoch 618/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 180.7946 - acc: 0.0291 - val_loss: 187.3483 - val_acc: 0.0481\n",
      "Epoch 619/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 180.3425 - acc: 0.0267 - val_loss: 187.6780 - val_acc: 0.0192\n",
      "Epoch 620/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 179.8488 - acc: 0.0364 - val_loss: 186.4416 - val_acc: 0.0481\n",
      "Epoch 621/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 179.3343 - acc: 0.0291 - val_loss: 186.5624 - val_acc: 0.0385\n",
      "Epoch 622/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 178.8157 - acc: 0.0340 - val_loss: 185.5892 - val_acc: 0.0385\n",
      "Epoch 623/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 178.3008 - acc: 0.0316 - val_loss: 185.4060 - val_acc: 0.0481\n",
      "Epoch 624/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 177.7946 - acc: 0.0316 - val_loss: 184.7494 - val_acc: 0.0481\n",
      "Epoch 625/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 177.2978 - acc: 0.0291 - val_loss: 184.2827 - val_acc: 0.0481\n",
      "Epoch 626/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 176.8086 - acc: 0.0291 - val_loss: 183.8774 - val_acc: 0.0481\n",
      "Epoch 627/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 176.3252 - acc: 0.0316 - val_loss: 183.1660 - val_acc: 0.0385\n",
      "Epoch 628/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 175.8470 - acc: 0.0316 - val_loss: 182.9965 - val_acc: 0.0481\n",
      "Epoch 629/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 175.3767 - acc: 0.0316 - val_loss: 182.0085 - val_acc: 0.0481\n",
      "Epoch 630/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 174.9232 - acc: 0.0291 - val_loss: 182.2600 - val_acc: 0.0481\n",
      "Epoch 631/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 174.5026 - acc: 0.0413 - val_loss: 180.8244 - val_acc: 0.0385\n",
      "Epoch 632/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 174.1561 - acc: 0.0340 - val_loss: 182.1104 - val_acc: 0.0385\n",
      "Epoch 633/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 173.9662 - acc: 0.0437 - val_loss: 179.9724 - val_acc: 0.0385\n",
      "Epoch 634/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 174.0651 - acc: 0.0364 - val_loss: 183.2993 - val_acc: 0.0577\n",
      "Epoch 635/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 174.4336 - acc: 0.0583 - val_loss: 179.7224 - val_acc: 0.0577\n",
      "Epoch 636/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 174.5007 - acc: 0.0558 - val_loss: 181.9287 - val_acc: 0.0577\n",
      "Epoch 637/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 173.1989 - acc: 0.0583 - val_loss: 177.8636 - val_acc: 0.0481\n",
      "Epoch 638/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 171.3200 - acc: 0.0340 - val_loss: 177.4117 - val_acc: 0.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/1000\n",
      "412/412 [==============================] - 0s 36us/step - loss: 170.8175 - acc: 0.0340 - val_loss: 179.8951 - val_acc: 0.0481\n",
      "Epoch 640/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 171.3735 - acc: 0.0655 - val_loss: 176.7494 - val_acc: 0.0288\n",
      "Epoch 641/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 171.0254 - acc: 0.0437 - val_loss: 177.4497 - val_acc: 0.0288\n",
      "Epoch 642/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 169.5812 - acc: 0.0485 - val_loss: 176.4249 - val_acc: 0.0481\n",
      "Epoch 643/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 168.9011 - acc: 0.0510 - val_loss: 175.2012 - val_acc: 0.0385\n",
      "Epoch 644/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 169.1697 - acc: 0.0364 - val_loss: 177.1011 - val_acc: 0.0481\n",
      "Epoch 645/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 168.8117 - acc: 0.0583 - val_loss: 174.2830 - val_acc: 0.0481\n",
      "Epoch 646/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 167.6884 - acc: 0.0364 - val_loss: 173.9217 - val_acc: 0.0481\n",
      "Epoch 647/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 167.1513 - acc: 0.0364 - val_loss: 175.2984 - val_acc: 0.0481\n",
      "Epoch 648/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 167.2246 - acc: 0.0631 - val_loss: 172.9531 - val_acc: 0.0192\n",
      "Epoch 649/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 166.7765 - acc: 0.0364 - val_loss: 173.3766 - val_acc: 0.0481\n",
      "Epoch 650/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 165.8715 - acc: 0.0534 - val_loss: 172.9593 - val_acc: 0.0481\n",
      "Epoch 651/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 165.4444 - acc: 0.0534 - val_loss: 171.6953 - val_acc: 0.0192\n",
      "Epoch 652/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 165.3656 - acc: 0.0437 - val_loss: 172.8325 - val_acc: 0.0288\n",
      "Epoch 653/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 164.8878 - acc: 0.0558 - val_loss: 171.0546 - val_acc: 0.0577\n",
      "Epoch 654/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 164.1433 - acc: 0.0437 - val_loss: 170.6399 - val_acc: 0.0577\n",
      "Epoch 655/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 163.7307 - acc: 0.0437 - val_loss: 171.4536 - val_acc: 0.0288\n",
      "Epoch 656/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 163.5448 - acc: 0.0534 - val_loss: 169.6933 - val_acc: 0.0385\n",
      "Epoch 657/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 163.1362 - acc: 0.0388 - val_loss: 170.0919 - val_acc: 0.0481\n",
      "Epoch 658/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 162.4913 - acc: 0.0583 - val_loss: 169.4211 - val_acc: 0.0577\n",
      "Epoch 659/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 162.0149 - acc: 0.0485 - val_loss: 168.5441 - val_acc: 0.0577\n",
      "Epoch 660/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 161.7578 - acc: 0.0413 - val_loss: 169.3860 - val_acc: 0.0288\n",
      "Epoch 661/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 161.4411 - acc: 0.0655 - val_loss: 167.8664 - val_acc: 0.0577\n",
      "Epoch 662/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 160.8664 - acc: 0.0461 - val_loss: 167.7791 - val_acc: 0.0673\n",
      "Epoch 663/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 160.3435 - acc: 0.0461 - val_loss: 168.0777 - val_acc: 0.0481\n",
      "Epoch 664/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 160.0239 - acc: 0.0680 - val_loss: 166.8122 - val_acc: 0.0481\n",
      "Epoch 665/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 159.6878 - acc: 0.0461 - val_loss: 167.0226 - val_acc: 0.0481\n",
      "Epoch 666/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 159.1997 - acc: 0.0728 - val_loss: 165.5501 - val_acc: 0.0577\n",
      "Epoch 667/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 158.6386 - acc: 0.0461 - val_loss: 164.9669 - val_acc: 0.0673\n",
      "Epoch 668/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 158.1599 - acc: 0.0510 - val_loss: 164.5390 - val_acc: 0.0577\n",
      "Epoch 669/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 157.8075 - acc: 0.0607 - val_loss: 163.4117 - val_acc: 0.0577\n",
      "Epoch 670/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 157.4913 - acc: 0.0485 - val_loss: 163.4938 - val_acc: 0.0481\n",
      "Epoch 671/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 157.1094 - acc: 0.0631 - val_loss: 162.2597 - val_acc: 0.0577\n",
      "Epoch 672/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 156.6545 - acc: 0.0510 - val_loss: 162.0740 - val_acc: 0.0577\n",
      "Epoch 673/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 156.1944 - acc: 0.0583 - val_loss: 161.5333 - val_acc: 0.0673\n",
      "Epoch 674/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 155.7856 - acc: 0.0558 - val_loss: 160.9363 - val_acc: 0.0577\n",
      "Epoch 675/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 155.4255 - acc: 0.0558 - val_loss: 161.0767 - val_acc: 0.0481\n",
      "Epoch 676/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 155.0740 - acc: 0.0680 - val_loss: 160.1825 - val_acc: 0.0577\n",
      "Epoch 677/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 154.6991 - acc: 0.0485 - val_loss: 160.4898 - val_acc: 0.0481\n",
      "Epoch 678/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 154.2918 - acc: 0.0655 - val_loss: 159.6189 - val_acc: 0.0577\n",
      "Epoch 679/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 153.8611 - acc: 0.0485 - val_loss: 159.7402 - val_acc: 0.0577\n",
      "Epoch 680/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 153.4291 - acc: 0.0704 - val_loss: 159.1960 - val_acc: 0.0673\n",
      "Epoch 681/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 153.0145 - acc: 0.0534 - val_loss: 159.0056 - val_acc: 0.0673\n",
      "Epoch 682/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 152.6230 - acc: 0.0558 - val_loss: 158.8330 - val_acc: 0.0577\n",
      "Epoch 683/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 152.2519 - acc: 0.0655 - val_loss: 158.3140 - val_acc: 0.0673\n",
      "Epoch 684/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 151.8953 - acc: 0.0510 - val_loss: 158.4149 - val_acc: 0.0577\n",
      "Epoch 685/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 151.5484 - acc: 0.0728 - val_loss: 157.5809 - val_acc: 0.0577\n",
      "Epoch 686/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 151.2105 - acc: 0.0510 - val_loss: 157.9101 - val_acc: 0.0769\n",
      "Epoch 687/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 150.8861 - acc: 0.0752 - val_loss: 156.7560 - val_acc: 0.0865\n",
      "Epoch 688/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 150.5876 - acc: 0.0607 - val_loss: 157.4569 - val_acc: 0.0577\n",
      "Epoch 689/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 150.3348 - acc: 0.0850 - val_loss: 155.9172 - val_acc: 0.0577\n",
      "Epoch 690/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 150.1526 - acc: 0.0752 - val_loss: 157.3412 - val_acc: 0.0962\n",
      "Epoch 691/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 150.0782 - acc: 0.0850 - val_loss: 155.3660 - val_acc: 0.0769\n",
      "Epoch 692/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 150.2359 - acc: 0.0850 - val_loss: 158.0363 - val_acc: 0.0865\n",
      "Epoch 693/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 150.4394 - acc: 0.0825 - val_loss: 154.9855 - val_acc: 0.0673\n",
      "Epoch 694/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 150.4082 - acc: 0.0922 - val_loss: 157.0141 - val_acc: 0.0865\n",
      "Epoch 695/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 149.6198 - acc: 0.0801 - val_loss: 153.3087 - val_acc: 0.0865\n",
      "Epoch 696/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 148.3020 - acc: 0.0850 - val_loss: 153.3046 - val_acc: 0.0673\n",
      "Epoch 697/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 147.2449 - acc: 0.0752 - val_loss: 153.3240 - val_acc: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 698/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 147.0574 - acc: 0.0850 - val_loss: 152.1970 - val_acc: 0.0769\n",
      "Epoch 699/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 147.3689 - acc: 0.0850 - val_loss: 154.3437 - val_acc: 0.1058\n",
      "Epoch 700/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 147.3861 - acc: 0.0850 - val_loss: 151.5044 - val_acc: 0.0769\n",
      "Epoch 701/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 146.7168 - acc: 0.0922 - val_loss: 152.0359 - val_acc: 0.0865\n",
      "Epoch 702/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 145.7645 - acc: 0.0874 - val_loss: 151.1113 - val_acc: 0.0769\n",
      "Epoch 703/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 145.2356 - acc: 0.0752 - val_loss: 150.3842 - val_acc: 0.0673\n",
      "Epoch 704/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 145.2386 - acc: 0.0777 - val_loss: 152.0436 - val_acc: 0.1154\n",
      "Epoch 705/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 145.2876 - acc: 0.0971 - val_loss: 149.8894 - val_acc: 0.0865\n",
      "Epoch 706/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 145.0094 - acc: 0.0947 - val_loss: 150.8742 - val_acc: 0.0962\n",
      "Epoch 707/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 144.3221 - acc: 0.0995 - val_loss: 149.3496 - val_acc: 0.0577\n",
      "Epoch 708/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 143.6737 - acc: 0.0680 - val_loss: 149.0029 - val_acc: 0.0865\n",
      "Epoch 709/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 143.3991 - acc: 0.0752 - val_loss: 149.9800 - val_acc: 0.1058\n",
      "Epoch 710/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 143.3819 - acc: 0.0995 - val_loss: 148.3630 - val_acc: 0.0962\n",
      "Epoch 711/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 143.4071 - acc: 0.1044 - val_loss: 149.9195 - val_acc: 0.1154\n",
      "Epoch 712/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 143.0745 - acc: 0.1019 - val_loss: 147.7540 - val_acc: 0.0962\n",
      "Epoch 713/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 142.5186 - acc: 0.1044 - val_loss: 148.2646 - val_acc: 0.1154\n",
      "Epoch 714/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 141.9045 - acc: 0.0971 - val_loss: 147.6933 - val_acc: 0.0962\n",
      "Epoch 715/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 141.5327 - acc: 0.0971 - val_loss: 146.9762 - val_acc: 0.0962\n",
      "Epoch 716/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 141.4121 - acc: 0.0898 - val_loss: 148.1120 - val_acc: 0.1250\n",
      "Epoch 717/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 141.3529 - acc: 0.1092 - val_loss: 146.4012 - val_acc: 0.1058\n",
      "Epoch 718/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 141.1916 - acc: 0.1165 - val_loss: 147.6279 - val_acc: 0.1250\n",
      "Epoch 719/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 140.8317 - acc: 0.1165 - val_loss: 145.8239 - val_acc: 0.1058\n",
      "Epoch 720/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 140.3583 - acc: 0.1141 - val_loss: 146.3027 - val_acc: 0.1250\n",
      "Epoch 721/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 139.8923 - acc: 0.1068 - val_loss: 145.5111 - val_acc: 0.0962\n",
      "Epoch 722/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 139.5365 - acc: 0.0995 - val_loss: 145.2899 - val_acc: 0.1058\n",
      "Epoch 723/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 139.2533 - acc: 0.1019 - val_loss: 145.4068 - val_acc: 0.1250\n",
      "Epoch 724/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 139.0276 - acc: 0.1092 - val_loss: 144.5411 - val_acc: 0.1154\n",
      "Epoch 725/1000\n",
      "412/412 [==============================] - 0s 32us/step - loss: 138.8535 - acc: 0.1141 - val_loss: 145.3855 - val_acc: 0.1346\n",
      "Epoch 726/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 138.6739 - acc: 0.1165 - val_loss: 143.9308 - val_acc: 0.1058\n",
      "Epoch 727/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 138.4627 - acc: 0.1311 - val_loss: 144.8819 - val_acc: 0.1250\n",
      "Epoch 728/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 138.1916 - acc: 0.1214 - val_loss: 143.2662 - val_acc: 0.1058\n",
      "Epoch 729/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 137.8933 - acc: 0.1383 - val_loss: 143.9998 - val_acc: 0.1538\n",
      "Epoch 730/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 137.5836 - acc: 0.1286 - val_loss: 142.4235 - val_acc: 0.1346\n",
      "Epoch 731/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 137.2633 - acc: 0.1432 - val_loss: 142.9959 - val_acc: 0.1538\n",
      "Epoch 732/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 136.9798 - acc: 0.1335 - val_loss: 141.4489 - val_acc: 0.1442\n",
      "Epoch 733/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 136.6931 - acc: 0.1505 - val_loss: 142.1071 - val_acc: 0.1538\n",
      "Epoch 734/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 136.4651 - acc: 0.1408 - val_loss: 140.3987 - val_acc: 0.1442\n",
      "Epoch 735/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 136.2287 - acc: 0.1626 - val_loss: 141.2209 - val_acc: 0.1538\n",
      "Epoch 736/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 136.1221 - acc: 0.1481 - val_loss: 139.1998 - val_acc: 0.1827\n",
      "Epoch 737/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 136.0191 - acc: 0.1699 - val_loss: 140.6508 - val_acc: 0.1731\n",
      "Epoch 738/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 135.9813 - acc: 0.1553 - val_loss: 138.2525 - val_acc: 0.1923\n",
      "Epoch 739/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 135.8384 - acc: 0.1626 - val_loss: 139.9412 - val_acc: 0.1731\n",
      "Epoch 740/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 135.6503 - acc: 0.1699 - val_loss: 137.2995 - val_acc: 0.2212\n",
      "Epoch 741/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 135.2132 - acc: 0.1748 - val_loss: 138.3465 - val_acc: 0.1731\n",
      "Epoch 742/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 134.6857 - acc: 0.1772 - val_loss: 136.4607 - val_acc: 0.1731\n",
      "Epoch 743/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 134.1767 - acc: 0.1772 - val_loss: 136.6779 - val_acc: 0.1635\n",
      "Epoch 744/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 133.7985 - acc: 0.1578 - val_loss: 135.7861 - val_acc: 0.1731\n",
      "Epoch 745/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 133.4906 - acc: 0.1772 - val_loss: 135.4125 - val_acc: 0.1635\n",
      "Epoch 746/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 133.2369 - acc: 0.1820 - val_loss: 135.2285 - val_acc: 0.1923\n",
      "Epoch 747/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 133.0199 - acc: 0.1699 - val_loss: 134.3503 - val_acc: 0.1731\n",
      "Epoch 748/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 132.8344 - acc: 0.1942 - val_loss: 134.7671 - val_acc: 0.2212\n",
      "Epoch 749/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 132.6812 - acc: 0.1869 - val_loss: 133.4055 - val_acc: 0.2115\n",
      "Epoch 750/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 132.6610 - acc: 0.2063 - val_loss: 134.8955 - val_acc: 0.1827\n",
      "Epoch 751/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 132.7156 - acc: 0.1917 - val_loss: 132.8279 - val_acc: 0.2019\n",
      "Epoch 752/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 132.9740 - acc: 0.1748 - val_loss: 135.6494 - val_acc: 0.1058\n",
      "Epoch 753/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 133.2419 - acc: 0.0777 - val_loss: 132.6479 - val_acc: 0.1250\n",
      "Epoch 754/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 133.5035 - acc: 0.1335 - val_loss: 135.5846 - val_acc: 0.0769\n",
      "Epoch 755/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 133.2417 - acc: 0.0243 - val_loss: 131.6539 - val_acc: 0.1731\n",
      "Epoch 756/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 132.5067 - acc: 0.1481 - val_loss: 132.7079 - val_acc: 0.2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 131.3414 - acc: 0.1990 - val_loss: 130.7643 - val_acc: 0.2885\n",
      "Epoch 758/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 130.5739 - acc: 0.2743 - val_loss: 130.3054 - val_acc: 0.2788\n",
      "Epoch 759/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 130.5787 - acc: 0.2621 - val_loss: 132.2140 - val_acc: 0.1731\n",
      "Epoch 760/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 130.9771 - acc: 0.1408 - val_loss: 130.0110 - val_acc: 0.1923\n",
      "Epoch 761/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 131.0816 - acc: 0.1699 - val_loss: 131.7487 - val_acc: 0.1538\n",
      "Epoch 762/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 130.6239 - acc: 0.1286 - val_loss: 129.2563 - val_acc: 0.2692\n",
      "Epoch 763/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 129.8726 - acc: 0.2743 - val_loss: 129.4271 - val_acc: 0.3654\n",
      "Epoch 764/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 129.3631 - acc: 0.3519 - val_loss: 129.6751 - val_acc: 0.3269\n",
      "Epoch 765/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 129.3106 - acc: 0.3034 - val_loss: 128.6046 - val_acc: 0.2788\n",
      "Epoch 766/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 129.4712 - acc: 0.2816 - val_loss: 130.2509 - val_acc: 0.1346\n",
      "Epoch 767/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 129.4662 - acc: 0.1019 - val_loss: 128.1665 - val_acc: 0.2981\n",
      "Epoch 768/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 129.1004 - acc: 0.2888 - val_loss: 128.8447 - val_acc: 0.3558\n",
      "Epoch 769/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 128.5952 - acc: 0.2985 - val_loss: 127.9056 - val_acc: 0.5096\n",
      "Epoch 770/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 128.2365 - acc: 0.4709 - val_loss: 127.5095 - val_acc: 0.4423\n",
      "Epoch 771/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 128.1360 - acc: 0.4126 - val_loss: 128.3999 - val_acc: 0.2885\n",
      "Epoch 772/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 128.1616 - acc: 0.2354 - val_loss: 127.0452 - val_acc: 0.2788\n",
      "Epoch 773/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 128.1220 - acc: 0.2888 - val_loss: 128.1810 - val_acc: 0.1635\n",
      "Epoch 774/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 127.9114 - acc: 0.1359 - val_loss: 126.6376 - val_acc: 0.3654\n",
      "Epoch 775/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 127.5677 - acc: 0.3471 - val_loss: 127.0684 - val_acc: 0.5481\n",
      "Epoch 776/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 127.2210 - acc: 0.4757 - val_loss: 126.5499 - val_acc: 0.6635\n",
      "Epoch 777/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 126.9791 - acc: 0.6019 - val_loss: 126.2023 - val_acc: 0.5962\n",
      "Epoch 778/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 126.8573 - acc: 0.5874 - val_loss: 126.7917 - val_acc: 0.4038\n",
      "Epoch 779/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 126.8033 - acc: 0.3641 - val_loss: 125.7677 - val_acc: 0.3654\n",
      "Epoch 780/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 126.7536 - acc: 0.3641 - val_loss: 126.8269 - val_acc: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 126.6630 - acc: 0.0000e+00 - val_loss: 125.4421 - val_acc: 0.3077\n",
      "Epoch 782/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 126.5141 - acc: 0.3034 - val_loss: 126.4109 - val_acc: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 126.3013 - acc: 0.0000e+00 - val_loss: 125.1651 - val_acc: 0.5962\n",
      "Epoch 784/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 126.0472 - acc: 0.5874 - val_loss: 125.6703 - val_acc: 0.6635\n",
      "Epoch 785/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 125.7999 - acc: 0.6019 - val_loss: 125.0771 - val_acc: 0.6731\n",
      "Epoch 786/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 125.5947 - acc: 0.6117 - val_loss: 125.0827 - val_acc: 0.6731\n",
      "Epoch 787/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 125.4333 - acc: 0.6117 - val_loss: 125.1586 - val_acc: 0.6731\n",
      "Epoch 788/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 125.3068 - acc: 0.6044 - val_loss: 124.7231 - val_acc: 0.6731\n",
      "Epoch 789/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 125.2040 - acc: 0.6117 - val_loss: 125.2912 - val_acc: 0.5000\n",
      "Epoch 790/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 125.1170 - acc: 0.4660 - val_loss: 124.4584 - val_acc: 0.5962\n",
      "Epoch 791/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 125.0429 - acc: 0.5316 - val_loss: 125.3880 - val_acc: 0.3077\n",
      "Epoch 792/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 124.9705 - acc: 0.3083 - val_loss: 124.2150 - val_acc: 0.3077\n",
      "Epoch 793/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 124.9121 - acc: 0.2597 - val_loss: 125.4292 - val_acc: 0.2404\n",
      "Epoch 794/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 124.8489 - acc: 0.2257 - val_loss: 123.9658 - val_acc: 0.1538\n",
      "Epoch 795/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 124.7820 - acc: 0.1481 - val_loss: 125.3844 - val_acc: 0.2115\n",
      "Epoch 796/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 124.7240 - acc: 0.1820 - val_loss: 123.7060 - val_acc: 0.0865\n",
      "Epoch 797/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 124.6607 - acc: 0.0777 - val_loss: 125.3079 - val_acc: 0.1827\n",
      "Epoch 798/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 124.6086 - acc: 0.1602 - val_loss: 123.4556 - val_acc: 0.0769\n",
      "Epoch 799/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 124.5872 - acc: 0.0413 - val_loss: 125.3077 - val_acc: 0.1346\n",
      "Epoch 800/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 124.5585 - acc: 0.1432 - val_loss: 123.2047 - val_acc: 0.0769\n",
      "Epoch 801/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 124.5282 - acc: 0.0316 - val_loss: 125.1552 - val_acc: 0.1250\n",
      "Epoch 802/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 124.4327 - acc: 0.1408 - val_loss: 122.8568 - val_acc: 0.0865\n",
      "Epoch 803/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 124.2800 - acc: 0.0534 - val_loss: 124.5239 - val_acc: 0.1923\n",
      "Epoch 804/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 124.0199 - acc: 0.1748 - val_loss: 122.3833 - val_acc: 0.2019\n",
      "Epoch 805/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 123.7192 - acc: 0.1820 - val_loss: 123.4569 - val_acc: 0.2692\n",
      "Epoch 806/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 123.3840 - acc: 0.2791 - val_loss: 121.9699 - val_acc: 0.3365\n",
      "Epoch 807/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 123.0573 - acc: 0.3252 - val_loss: 122.1985 - val_acc: 0.3846\n",
      "Epoch 808/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 122.8207 - acc: 0.3471 - val_loss: 121.8869 - val_acc: 0.3654\n",
      "Epoch 809/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 122.6864 - acc: 0.3350 - val_loss: 121.0807 - val_acc: 0.2981\n",
      "Epoch 810/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 122.6530 - acc: 0.3010 - val_loss: 121.7515 - val_acc: 0.2788\n",
      "Epoch 811/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 122.6874 - acc: 0.2718 - val_loss: 120.2776 - val_acc: 0.2404\n",
      "Epoch 812/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 122.7806 - acc: 0.2112 - val_loss: 121.8107 - val_acc: 0.2115\n",
      "Epoch 813/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 122.8962 - acc: 0.2112 - val_loss: 119.7394 - val_acc: 0.1538\n",
      "Epoch 814/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 123.0068 - acc: 0.1505 - val_loss: 122.0097 - val_acc: 0.1827\n",
      "Epoch 815/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 123.0594 - acc: 0.1626 - val_loss: 119.3245 - val_acc: 0.1346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 123.0346 - acc: 0.1238 - val_loss: 121.8183 - val_acc: 0.1827\n",
      "Epoch 817/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 122.8402 - acc: 0.1602 - val_loss: 119.0352 - val_acc: 0.2019\n",
      "Epoch 818/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 122.5121 - acc: 0.1917 - val_loss: 120.6353 - val_acc: 0.2019\n",
      "Epoch 819/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 122.0804 - acc: 0.2233 - val_loss: 118.7083 - val_acc: 0.2596\n",
      "Epoch 820/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 121.6909 - acc: 0.2476 - val_loss: 119.2690 - val_acc: 0.2596\n",
      "Epoch 821/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 121.3977 - acc: 0.2451 - val_loss: 118.9201 - val_acc: 0.2404\n",
      "Epoch 822/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 121.2606 - acc: 0.2451 - val_loss: 118.4875 - val_acc: 0.2404\n",
      "Epoch 823/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 121.2591 - acc: 0.2209 - val_loss: 119.5190 - val_acc: 0.2500\n",
      "Epoch 824/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 121.3199 - acc: 0.2184 - val_loss: 118.2812 - val_acc: 0.2212\n",
      "Epoch 825/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 121.4117 - acc: 0.2330 - val_loss: 120.0583 - val_acc: 0.2212\n",
      "Epoch 826/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 121.4490 - acc: 0.2184 - val_loss: 118.2386 - val_acc: 0.2115\n",
      "Epoch 827/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 121.3783 - acc: 0.2160 - val_loss: 119.9041 - val_acc: 0.2212\n",
      "Epoch 828/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 121.2093 - acc: 0.2112 - val_loss: 118.1645 - val_acc: 0.2115\n",
      "Epoch 829/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.9692 - acc: 0.2087 - val_loss: 119.1960 - val_acc: 0.2212\n",
      "Epoch 830/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 120.7262 - acc: 0.2087 - val_loss: 118.2343 - val_acc: 0.1923\n",
      "Epoch 831/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.5223 - acc: 0.1917 - val_loss: 118.4897 - val_acc: 0.1827\n",
      "Epoch 832/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 120.3870 - acc: 0.2015 - val_loss: 118.5579 - val_acc: 0.1923\n",
      "Epoch 833/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 120.3199 - acc: 0.2039 - val_loss: 118.0941 - val_acc: 0.2019\n",
      "Epoch 834/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 120.2994 - acc: 0.1869 - val_loss: 118.9497 - val_acc: 0.1827\n",
      "Epoch 835/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 120.2987 - acc: 0.1917 - val_loss: 117.9445 - val_acc: 0.2115\n",
      "Epoch 836/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 120.2959 - acc: 0.1772 - val_loss: 119.2376 - val_acc: 0.1827\n",
      "Epoch 837/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.2888 - acc: 0.1845 - val_loss: 117.8863 - val_acc: 0.1827\n",
      "Epoch 838/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 120.2580 - acc: 0.1845 - val_loss: 119.3557 - val_acc: 0.1827\n",
      "Epoch 839/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.2135 - acc: 0.1820 - val_loss: 117.8422 - val_acc: 0.1827\n",
      "Epoch 840/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 120.1409 - acc: 0.1772 - val_loss: 119.2866 - val_acc: 0.1731\n",
      "Epoch 841/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.0588 - acc: 0.1772 - val_loss: 117.7860 - val_acc: 0.1827\n",
      "Epoch 842/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 119.9547 - acc: 0.1578 - val_loss: 119.0420 - val_acc: 0.1635\n",
      "Epoch 843/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 119.8358 - acc: 0.1772 - val_loss: 117.7388 - val_acc: 0.1827\n",
      "Epoch 844/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 119.7114 - acc: 0.1626 - val_loss: 118.7028 - val_acc: 0.1442\n",
      "Epoch 845/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 119.5897 - acc: 0.1723 - val_loss: 117.7189 - val_acc: 0.1635\n",
      "Epoch 846/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 119.4854 - acc: 0.1602 - val_loss: 118.4192 - val_acc: 0.1442\n",
      "Epoch 847/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 119.3810 - acc: 0.1578 - val_loss: 117.6969 - val_acc: 0.1538\n",
      "Epoch 848/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 119.2860 - acc: 0.1456 - val_loss: 118.1262 - val_acc: 0.1346\n",
      "Epoch 849/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 119.1968 - acc: 0.1602 - val_loss: 117.5673 - val_acc: 0.1538\n",
      "Epoch 850/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 119.1162 - acc: 0.1408 - val_loss: 117.8935 - val_acc: 0.1154\n",
      "Epoch 851/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 119.0403 - acc: 0.1456 - val_loss: 117.3778 - val_acc: 0.1442\n",
      "Epoch 852/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 118.9721 - acc: 0.1383 - val_loss: 117.7646 - val_acc: 0.1154\n",
      "Epoch 853/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 118.9115 - acc: 0.1408 - val_loss: 117.1495 - val_acc: 0.1538\n",
      "Epoch 854/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 118.8621 - acc: 0.1335 - val_loss: 117.7844 - val_acc: 0.1250\n",
      "Epoch 855/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 118.8311 - acc: 0.1359 - val_loss: 116.9030 - val_acc: 0.1538\n",
      "Epoch 856/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 118.8277 - acc: 0.1383 - val_loss: 118.0480 - val_acc: 0.1442\n",
      "Epoch 857/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 118.8740 - acc: 0.1481 - val_loss: 116.6919 - val_acc: 0.1635\n",
      "Epoch 858/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 119.0226 - acc: 0.1408 - val_loss: 119.0336 - val_acc: 0.1635\n",
      "Epoch 859/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 119.3776 - acc: 0.1481 - val_loss: 116.9427 - val_acc: 0.1346\n",
      "Epoch 860/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 120.0680 - acc: 0.1456 - val_loss: 121.6990 - val_acc: 0.1346\n",
      "Epoch 861/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 121.1830 - acc: 0.1092 - val_loss: 118.4490 - val_acc: 0.0962\n",
      "Epoch 862/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 122.6291 - acc: 0.0801 - val_loss: 125.0568 - val_acc: 0.0577\n",
      "Epoch 863/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 123.7469 - acc: 0.0777 - val_loss: 118.7360 - val_acc: 0.0962\n",
      "Epoch 864/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 123.1218 - acc: 0.0583 - val_loss: 120.9884 - val_acc: 0.1346\n",
      "Epoch 865/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 120.6024 - acc: 0.1214 - val_loss: 116.1798 - val_acc: 0.1250\n",
      "Epoch 866/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 118.3571 - acc: 0.1262 - val_loss: 116.1154 - val_acc: 0.1442\n",
      "Epoch 867/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 118.4617 - acc: 0.1408 - val_loss: 120.3376 - val_acc: 0.1346\n",
      "Epoch 868/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 120.0605 - acc: 0.1189 - val_loss: 117.0372 - val_acc: 0.0865\n",
      "Epoch 869/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 120.6739 - acc: 0.1189 - val_loss: 119.5173 - val_acc: 0.1538\n",
      "Epoch 870/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 119.4415 - acc: 0.1383 - val_loss: 116.0499 - val_acc: 0.1538\n",
      "Epoch 871/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 117.9976 - acc: 0.1214 - val_loss: 115.9372 - val_acc: 0.1346\n",
      "Epoch 872/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 118.1570 - acc: 0.1262 - val_loss: 119.3077 - val_acc: 0.1442\n",
      "Epoch 873/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 119.2130 - acc: 0.1335 - val_loss: 116.2730 - val_acc: 0.1250\n",
      "Epoch 874/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 119.3064 - acc: 0.1238 - val_loss: 117.7634 - val_acc: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 118.2205 - acc: 0.1286 - val_loss: 116.3126 - val_acc: 0.1058\n",
      "Epoch 876/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.6139 - acc: 0.1044 - val_loss: 115.8210 - val_acc: 0.1538\n",
      "Epoch 877/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 118.1439 - acc: 0.1286 - val_loss: 118.5903 - val_acc: 0.1346\n",
      "Epoch 878/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 118.6088 - acc: 0.1286 - val_loss: 115.7591 - val_acc: 0.1442\n",
      "Epoch 879/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 118.1996 - acc: 0.1189 - val_loss: 116.6022 - val_acc: 0.1058\n",
      "Epoch 880/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.4782 - acc: 0.1019 - val_loss: 116.5887 - val_acc: 0.1058\n",
      "Epoch 881/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 117.4388 - acc: 0.0995 - val_loss: 115.5940 - val_acc: 0.1346\n",
      "Epoch 882/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.8791 - acc: 0.1238 - val_loss: 117.7100 - val_acc: 0.0962\n",
      "Epoch 883/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 117.9123 - acc: 0.1286 - val_loss: 115.5225 - val_acc: 0.1250\n",
      "Epoch 884/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.4555 - acc: 0.1068 - val_loss: 115.9148 - val_acc: 0.0865\n",
      "Epoch 885/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.1393 - acc: 0.0971 - val_loss: 116.6642 - val_acc: 0.1250\n",
      "Epoch 886/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 117.3021 - acc: 0.1092 - val_loss: 115.4386 - val_acc: 0.1154\n",
      "Epoch 887/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 117.5176 - acc: 0.1238 - val_loss: 116.9441 - val_acc: 0.0962\n",
      "Epoch 888/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 117.3478 - acc: 0.1165 - val_loss: 115.5816 - val_acc: 0.1154\n",
      "Epoch 889/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 117.0289 - acc: 0.0995 - val_loss: 115.6780 - val_acc: 0.1154\n",
      "Epoch 890/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 116.9416 - acc: 0.0995 - val_loss: 116.6370 - val_acc: 0.1058\n",
      "Epoch 891/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 117.0805 - acc: 0.1044 - val_loss: 115.3815 - val_acc: 0.1058\n",
      "Epoch 892/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 117.1319 - acc: 0.1044 - val_loss: 116.5816 - val_acc: 0.1058\n",
      "Epoch 893/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.9741 - acc: 0.0947 - val_loss: 115.6622 - val_acc: 0.1154\n",
      "Epoch 894/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 116.7817 - acc: 0.0947 - val_loss: 115.6295 - val_acc: 0.1154\n",
      "Epoch 895/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 116.7411 - acc: 0.0947 - val_loss: 116.4652 - val_acc: 0.1058\n",
      "Epoch 896/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 116.8095 - acc: 0.0971 - val_loss: 115.2865 - val_acc: 0.1154\n",
      "Epoch 897/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.8227 - acc: 0.1019 - val_loss: 116.3798 - val_acc: 0.1058\n",
      "Epoch 898/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 116.7141 - acc: 0.0850 - val_loss: 115.5377 - val_acc: 0.1154\n",
      "Epoch 899/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 116.5929 - acc: 0.0995 - val_loss: 115.5648 - val_acc: 0.1058\n",
      "Epoch 900/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 116.5521 - acc: 0.0947 - val_loss: 116.1659 - val_acc: 0.1058\n",
      "Epoch 901/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.5797 - acc: 0.0801 - val_loss: 115.2477 - val_acc: 0.1058\n",
      "Epoch 902/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 116.5894 - acc: 0.0971 - val_loss: 116.1620 - val_acc: 0.1058\n",
      "Epoch 903/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.5291 - acc: 0.0801 - val_loss: 115.4226 - val_acc: 0.1058\n",
      "Epoch 904/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 116.4440 - acc: 0.0898 - val_loss: 115.5818 - val_acc: 0.0769\n",
      "Epoch 905/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 116.3943 - acc: 0.0825 - val_loss: 115.9042 - val_acc: 0.1058\n",
      "Epoch 906/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 116.3939 - acc: 0.0825 - val_loss: 115.2501 - val_acc: 0.0962\n",
      "Epoch 907/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.4011 - acc: 0.0922 - val_loss: 116.0556 - val_acc: 0.1058\n",
      "Epoch 908/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 116.3719 - acc: 0.0777 - val_loss: 115.3244 - val_acc: 0.1058\n",
      "Epoch 909/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 116.3092 - acc: 0.0874 - val_loss: 115.6702 - val_acc: 0.0769\n",
      "Epoch 910/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 116.2524 - acc: 0.0752 - val_loss: 115.6706 - val_acc: 0.0769\n",
      "Epoch 911/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.2244 - acc: 0.0752 - val_loss: 115.3342 - val_acc: 0.1058\n",
      "Epoch 912/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 116.2167 - acc: 0.0874 - val_loss: 115.9189 - val_acc: 0.1058\n",
      "Epoch 913/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.2058 - acc: 0.0777 - val_loss: 115.2830 - val_acc: 0.0962\n",
      "Epoch 914/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 116.1733 - acc: 0.0874 - val_loss: 115.7759 - val_acc: 0.0673\n",
      "Epoch 915/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 116.1275 - acc: 0.0825 - val_loss: 115.4627 - val_acc: 0.0769\n",
      "Epoch 916/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.0854 - acc: 0.0825 - val_loss: 115.4754 - val_acc: 0.0769\n",
      "Epoch 917/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 116.0579 - acc: 0.0825 - val_loss: 115.7155 - val_acc: 0.0769\n",
      "Epoch 918/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.0419 - acc: 0.0728 - val_loss: 115.3207 - val_acc: 0.1058\n",
      "Epoch 919/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 116.0253 - acc: 0.0874 - val_loss: 115.7721 - val_acc: 0.0673\n",
      "Epoch 920/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.9997 - acc: 0.0752 - val_loss: 115.3514 - val_acc: 0.0962\n",
      "Epoch 921/1000\n",
      "412/412 [==============================] - 0s 29us/step - loss: 115.9667 - acc: 0.0850 - val_loss: 115.6126 - val_acc: 0.0769\n",
      "Epoch 922/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.9323 - acc: 0.0777 - val_loss: 115.5164 - val_acc: 0.0673\n",
      "Epoch 923/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.9039 - acc: 0.0850 - val_loss: 115.4069 - val_acc: 0.0769\n",
      "Epoch 924/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 115.8829 - acc: 0.0777 - val_loss: 115.6622 - val_acc: 0.0769\n",
      "Epoch 925/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.8655 - acc: 0.0752 - val_loss: 115.2951 - val_acc: 0.0962\n",
      "Epoch 926/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.8471 - acc: 0.0850 - val_loss: 115.7055 - val_acc: 0.0673\n",
      "Epoch 927/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.8261 - acc: 0.0680 - val_loss: 115.2778 - val_acc: 0.0962\n",
      "Epoch 928/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 115.7997 - acc: 0.0850 - val_loss: 115.6125 - val_acc: 0.0769\n",
      "Epoch 929/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.7701 - acc: 0.0752 - val_loss: 115.3514 - val_acc: 0.0769\n",
      "Epoch 930/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.7406 - acc: 0.0728 - val_loss: 115.4441 - val_acc: 0.0673\n",
      "Epoch 931/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.7144 - acc: 0.0825 - val_loss: 115.4700 - val_acc: 0.0673\n",
      "Epoch 932/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 115.6927 - acc: 0.0777 - val_loss: 115.2869 - val_acc: 0.0769\n",
      "Epoch 933/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.6746 - acc: 0.0777 - val_loss: 115.5527 - val_acc: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.6563 - acc: 0.0752 - val_loss: 115.2121 - val_acc: 0.0865\n",
      "Epoch 935/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.6364 - acc: 0.0825 - val_loss: 115.5415 - val_acc: 0.0769\n",
      "Epoch 936/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 115.6148 - acc: 0.0752 - val_loss: 115.1875 - val_acc: 0.0865\n",
      "Epoch 937/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.5928 - acc: 0.0801 - val_loss: 115.4999 - val_acc: 0.0769\n",
      "Epoch 938/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.5728 - acc: 0.0752 - val_loss: 115.1538 - val_acc: 0.0865\n",
      "Epoch 939/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 115.5521 - acc: 0.0801 - val_loss: 115.4723 - val_acc: 0.0673\n",
      "Epoch 940/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 115.5338 - acc: 0.0704 - val_loss: 115.1121 - val_acc: 0.0865\n",
      "Epoch 941/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.5139 - acc: 0.0825 - val_loss: 115.4585 - val_acc: 0.0673\n",
      "Epoch 942/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.4972 - acc: 0.0680 - val_loss: 115.0680 - val_acc: 0.0769\n",
      "Epoch 943/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 115.4777 - acc: 0.0825 - val_loss: 115.4267 - val_acc: 0.0673\n",
      "Epoch 944/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 115.4570 - acc: 0.0655 - val_loss: 115.0678 - val_acc: 0.0865\n",
      "Epoch 945/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 115.4336 - acc: 0.0801 - val_loss: 115.3451 - val_acc: 0.0673\n",
      "Epoch 946/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.4083 - acc: 0.0728 - val_loss: 115.0943 - val_acc: 0.0769\n",
      "Epoch 947/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.3850 - acc: 0.0728 - val_loss: 115.2595 - val_acc: 0.0673\n",
      "Epoch 948/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.3621 - acc: 0.0752 - val_loss: 115.1241 - val_acc: 0.0673\n",
      "Epoch 949/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 115.3408 - acc: 0.0728 - val_loss: 115.1811 - val_acc: 0.0673\n",
      "Epoch 950/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.3205 - acc: 0.0728 - val_loss: 115.1392 - val_acc: 0.0673\n",
      "Epoch 951/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.3011 - acc: 0.0752 - val_loss: 115.1221 - val_acc: 0.0673\n",
      "Epoch 952/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 115.2823 - acc: 0.0728 - val_loss: 115.1715 - val_acc: 0.0673\n",
      "Epoch 953/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.2646 - acc: 0.0728 - val_loss: 115.0536 - val_acc: 0.0673\n",
      "Epoch 954/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 115.2479 - acc: 0.0728 - val_loss: 115.2133 - val_acc: 0.0673\n",
      "Epoch 955/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.2319 - acc: 0.0752 - val_loss: 114.9942 - val_acc: 0.0769\n",
      "Epoch 956/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.2168 - acc: 0.0680 - val_loss: 115.2476 - val_acc: 0.0577\n",
      "Epoch 957/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 115.2015 - acc: 0.0704 - val_loss: 114.9346 - val_acc: 0.0673\n",
      "Epoch 958/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.1886 - acc: 0.0752 - val_loss: 115.2883 - val_acc: 0.0673\n",
      "Epoch 959/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 115.1745 - acc: 0.0680 - val_loss: 114.8681 - val_acc: 0.0769\n",
      "Epoch 960/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.1640 - acc: 0.0777 - val_loss: 115.3727 - val_acc: 0.0673\n",
      "Epoch 961/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 115.1622 - acc: 0.0583 - val_loss: 114.7402 - val_acc: 0.1058\n",
      "Epoch 962/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.1678 - acc: 0.0752 - val_loss: 115.5427 - val_acc: 0.0865\n",
      "Epoch 963/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.1863 - acc: 0.0655 - val_loss: 114.5989 - val_acc: 0.0962\n",
      "Epoch 964/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 115.2141 - acc: 0.0777 - val_loss: 115.8012 - val_acc: 0.0962\n",
      "Epoch 965/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.2624 - acc: 0.0704 - val_loss: 114.4625 - val_acc: 0.0962\n",
      "Epoch 966/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 115.3463 - acc: 0.0874 - val_loss: 116.2629 - val_acc: 0.0769\n",
      "Epoch 967/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.4582 - acc: 0.0850 - val_loss: 114.3820 - val_acc: 0.1058\n",
      "Epoch 968/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 115.6267 - acc: 0.0947 - val_loss: 116.9396 - val_acc: 0.0865\n",
      "Epoch 969/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.8089 - acc: 0.0971 - val_loss: 114.4060 - val_acc: 0.1058\n",
      "Epoch 970/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 116.0167 - acc: 0.0825 - val_loss: 117.5354 - val_acc: 0.0962\n",
      "Epoch 971/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.1545 - acc: 0.0995 - val_loss: 114.4378 - val_acc: 0.1058\n",
      "Epoch 972/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.2078 - acc: 0.0898 - val_loss: 117.4290 - val_acc: 0.0962\n",
      "Epoch 973/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 116.0752 - acc: 0.0947 - val_loss: 114.3333 - val_acc: 0.1058\n",
      "Epoch 974/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 115.8146 - acc: 0.0874 - val_loss: 116.3795 - val_acc: 0.0769\n",
      "Epoch 975/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 115.4442 - acc: 0.0825 - val_loss: 114.3851 - val_acc: 0.0769\n",
      "Epoch 976/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.1156 - acc: 0.0801 - val_loss: 115.1577 - val_acc: 0.0673\n",
      "Epoch 977/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 114.9018 - acc: 0.0510 - val_loss: 114.9045 - val_acc: 0.0769\n",
      "Epoch 978/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 114.8441 - acc: 0.0704 - val_loss: 114.4939 - val_acc: 0.0962\n",
      "Epoch 979/1000\n",
      "412/412 [==============================] - 0s 19us/step - loss: 114.9166 - acc: 0.0728 - val_loss: 115.6481 - val_acc: 0.0962\n",
      "Epoch 980/1000\n",
      "412/412 [==============================] - 0s 15us/step - loss: 115.0420 - acc: 0.0680 - val_loss: 114.2709 - val_acc: 0.0962\n",
      "Epoch 981/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 115.1807 - acc: 0.0850 - val_loss: 116.1362 - val_acc: 0.0769\n",
      "Epoch 982/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.2543 - acc: 0.0850 - val_loss: 114.2277 - val_acc: 0.0962\n",
      "Epoch 983/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.2714 - acc: 0.0850 - val_loss: 116.0469 - val_acc: 0.0769\n",
      "Epoch 984/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 115.1889 - acc: 0.0825 - val_loss: 114.2499 - val_acc: 0.0962\n",
      "Epoch 985/1000\n",
      "412/412 [==============================] - 0s 5us/step - loss: 115.0631 - acc: 0.0850 - val_loss: 115.4914 - val_acc: 0.0962\n",
      "Epoch 986/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 114.9119 - acc: 0.0704 - val_loss: 114.3942 - val_acc: 0.0962\n",
      "Epoch 987/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 114.7865 - acc: 0.0728 - val_loss: 114.8769 - val_acc: 0.0673\n",
      "Epoch 988/1000\n",
      "412/412 [==============================] - 0s 27us/step - loss: 114.6995 - acc: 0.0607 - val_loss: 114.6836 - val_acc: 0.0769\n",
      "Epoch 989/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 114.6647 - acc: 0.0704 - val_loss: 114.4500 - val_acc: 0.0769\n",
      "Epoch 990/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 114.6771 - acc: 0.0777 - val_loss: 115.0634 - val_acc: 0.0769\n",
      "Epoch 991/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 114.7123 - acc: 0.0631 - val_loss: 114.2732 - val_acc: 0.0962\n",
      "Epoch 992/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 114.7531 - acc: 0.0752 - val_loss: 115.3021 - val_acc: 0.0865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993/1000\n",
      "412/412 [==============================] - 0s 12us/step - loss: 114.7738 - acc: 0.0583 - val_loss: 114.2166 - val_acc: 0.0769\n",
      "Epoch 994/1000\n",
      "412/412 [==============================] - 0s 24us/step - loss: 114.7945 - acc: 0.0752 - val_loss: 115.3779 - val_acc: 0.0962\n",
      "Epoch 995/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 114.7776 - acc: 0.0680 - val_loss: 114.2092 - val_acc: 0.0769\n",
      "Epoch 996/1000\n",
      "412/412 [==============================] - 0s 7us/step - loss: 114.7489 - acc: 0.0728 - val_loss: 115.2138 - val_acc: 0.0865\n",
      "Epoch 997/1000\n",
      "412/412 [==============================] - 0s 22us/step - loss: 114.6896 - acc: 0.0631 - val_loss: 114.2476 - val_acc: 0.0962\n",
      "Epoch 998/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 114.6256 - acc: 0.0752 - val_loss: 114.8653 - val_acc: 0.0769\n",
      "Epoch 999/1000\n",
      "412/412 [==============================] - 0s 10us/step - loss: 114.5617 - acc: 0.0510 - val_loss: 114.3717 - val_acc: 0.0673\n",
      "Epoch 1000/1000\n",
      "412/412 [==============================] - 0s 17us/step - loss: 114.5119 - acc: 0.0704 - val_loss: 114.4999 - val_acc: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b75d0b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test,y_test),\n",
    "epochs=1000, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter your height:170\n",
      "please enter your mass:70\n",
      "female:0 or male:1 =1\n",
      "your bmi: 24.221453287197235\n"
     ]
    }
   ],
   "source": [
    "height=int(input(\"please enter your height:\"))\n",
    "mass=int(input(\"please enter your mass:\"))\n",
    "gender=int(input(\"female:0 or male:1 =\"))\n",
    "height1 = height/100\n",
    "bmi=mass/(height1*height1)\n",
    "print(\"your bmi:\",bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.array([[mass,height,gender,bmi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.        , 170.        ,   1.        ,  24.22145329])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reshape(4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53.084076]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Personal_trainer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
